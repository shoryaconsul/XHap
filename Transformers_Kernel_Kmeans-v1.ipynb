{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modified objective function with the addition of a trace regularization, to force the diagonal elements of W to zero.\n",
    "2. Changed activation function to softmax with regularization 1/T*||W-s||_F where S is the the dissimilarity matrix as defined in SDHap.\n",
    "3. Used kernel k-means to determine haplotype memberships.\n",
    "\n",
    "Successor to Transformers_v8 (using Goemans-Williamson algorithm when determining haplotype memberships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rn\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from os import path\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "from typing import Any, List, Tuple\n",
    "from nptyping import NDArray\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import cvxpy as cp\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from read_embeddings import save_ckp, load_ckp, MyFilter, \\\n",
    "    ReadAE, SNVMatrixDataset, learn_embed\n",
    "from ScheduleOptim import ScheduledOptim\n",
    "from helper import read_hap, read_true_hap, compute_cpr\n",
    "from kernel_kmeans import KernelKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrTransformer(nn.Module):\n",
    "    def __init__(self, d_model: int=512, d_qk: int=None):\n",
    "        super().__init__()\n",
    "        d_ff = 4*d_model  # Dimension of intermediate feedforward layer\n",
    "        n_head = 4  # Number of attention heads\n",
    "        if d_qk is None:\n",
    "            d_qk = int(d_model//n_head)  # Dim of query and key vectors in last attn layer\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_qk = d_qk\n",
    "        encoderLayer = nn.TransformerEncoderLayer(d_model, n_head, d_ff,\n",
    "                                                  batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoderLayer, num_layers=2)\n",
    "        self.attn_lastq = nn.Linear(d_model, d_qk)\n",
    "#         self.attn_lastk = nn.Linear(d_model, d_qk)\n",
    "#         self.activation = nn.Tanh()\n",
    "#         self.activation = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder(x)\n",
    "        lastq = self.attn_lastq(x_enc)\n",
    "        Z = F.normalize(lastq, 2, dim=2)\n",
    "        \n",
    "        return torch.matmul(Z, Z.transpose(1,2))\n",
    "\n",
    "#         lastk = self.attn_lastk(x_enc)\n",
    "#         Z = self.activation(torch.matmul(lastq, lastk.transpose(1,2))\n",
    "#                             /np.sqrt(self.d_qk))\n",
    "#         return 0.5*(Z + Z.transpose(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_memhap(SNVdataset: SNVMatrixDataset,\n",
    "               ae: ReadAE, xformer: CorrTransformer\n",
    "               ):\n",
    "\n",
    "    m = len(SNVdataset)\n",
    "    dataloader_full = DataLoader(SNVdataset, batch_size=m,\n",
    "                                num_workers=0)\n",
    "    for i, (data, idx) in enumerate(dataloader_full):\n",
    "        SNV_onehot = data\n",
    "        \n",
    "    ae.eval()  # Set eval flags\n",
    "    xformer.eval()  \n",
    "    \n",
    "    embed, _ = ae(SNV_onehot)  # Read embeddings\n",
    "    W_full = xformer(embed[None,:]).detach().numpy()  # Converting to numpy\n",
    "    W_full = W_full[0]  # Removing dummy dimension\n",
    "\n",
    "    kmeans = KernelKMeans(n_clusters=2, max_iter=1000, tol=1e-3)\n",
    "    kmeans.fit(W_full)\n",
    "    return 2*kmeans.labels_ - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ACGT statistics of a read matrix\n",
    "def ACGT_count(submatrix: NDArray[(Any, Any), int]):\n",
    "    out = np.zeros((submatrix.shape[1], 4))\n",
    "    for i in range(4):\n",
    "        out[:, i] = (submatrix == (i + 1)).sum(axis = 0)\n",
    "\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def origin2hap(SNV_matrix: NDArray[(Any, Any), int], origin: NDArray[int],\n",
    "              num_hap: int=2) -> NDArray[(Any, Any), int]:    \n",
    "    \"\"\"\n",
    "    SNV_matrix:\n",
    "        Full read-SNV matrix\n",
    "    origin: \n",
    "        Specifies origin of each read by an int from (0, 1, ..., num_hap-1)\n",
    "        \n",
    "    Returns\n",
    "        matrix of haplotypes (haplotypes x SNPs)\n",
    "    \"\"\"\n",
    "    \n",
    "    origin_val = np.unique(origin)\n",
    "    accepted_val = np.arange(num_hap)\n",
    "    if np.any(np.intersect1d(origin_val, accepted_val) != origin_val):\n",
    "    \traise ValueError(\"Invalid origin values passed as argument.\")\n",
    "\n",
    "    hap_matrix = np.zeros((num_hap, SNV_matrix.shape[1]), dtype=int)\n",
    "    ACGTcount = ACGT_count(SNV_matrix)  # Stats of entire read matrix\n",
    "    for h in range(num_hap):\n",
    "        reads_h = SNV_matrix[origin == h]  # Reads attributed to haplotype i\n",
    "        h_stats = np.zeros((SNV_matrix.shape[1], 4))\n",
    "        \n",
    "        if len(reads_h) != 0:\n",
    "            h_stats = ACGT_count(reads_h) # ACGT statistics of a single nucleotide position\n",
    "        hap_matrix[h, :] = np.argmax(h_stats, axis = 1) + 1  # Most commonly occuring base at each pos  \n",
    "        \n",
    "        uncov_pos = np.where(np.sum(h_stats, axis = 1) == 0)[0]  # Positions uncovered by reads\n",
    "        for j in range(len(uncov_pos)):  # if not covered, select the most doninant one based on 'ACGTcount'  \n",
    "            base_max = np.flatnonzero(ACGTcount[uncov_pos[j], :] == np.amax(ACGTcount[uncov_pos[j], :])) + 1\n",
    "            if len(base_max) == 1:  # Single dominant base\n",
    "                hap_matrix[h, uncov_pos[j]] == base_max[0]\n",
    "            else:  # Choose one of the dominant bases at random\n",
    "                hap_matrix[h, uncov_pos[j]] = np.random.choice(base_max)\n",
    "\n",
    "    return hap_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(read, haplo):\n",
    "    return sum((haplo - read)[read != 0] != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MEC(SNV_matrix: NDArray[(Any, Any), int],\n",
    "        hap_matrix: NDArray[(Any, Any), int]) -> float:  # Compute MEC score\n",
    "    res = 0\n",
    "    \n",
    "    for SNV_read in SNV_matrix:\n",
    "        dis = [hamming_distance(SNV_read, hap) for j, hap in enumerate(hap_matrix)]\n",
    "        res = res + min(dis)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readW(SNVdataset: SNVMatrixDataset, \n",
    "          ae: ReadAE, xformer: CorrTransformer\n",
    "         ) -> NDArray[(Any, Any), float]:\n",
    "    \n",
    "    m = len(SNVdataset)\n",
    "    dataloader_full = DataLoader(SNVdataset, batch_size=m,\n",
    "                                num_workers=0)\n",
    "    for i, (data, idx) in enumerate(dataloader_full):\n",
    "        SNV_onehot = data\n",
    "        \n",
    "    ae.eval()  # Set eval flags\n",
    "    xformer.eval()  \n",
    "    \n",
    "    embed, _ = ae(SNV_onehot)  # Read embeddings\n",
    "    W_full = xformer(embed[None,:]).detach().numpy()  # Converting to numpy\n",
    "    return W_full[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine(hap_matrix: NDArray[(Any, Any), int],\n",
    "           SNV_matrix: NDArray[(Any, Any), int],\n",
    "           verbose=False\n",
    "          ) -> NDArray[(Any, Any), int]: \n",
    "    \"\"\"\n",
    "    This function greedily refines the haplotype matrix by iterating through the\n",
    "    SNPs and flipping the haplotype bases. The flip is accepted (greedily) if it\n",
    "    improves the MEC score.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    hap_matrix_greedy = deepcopy(hap_matrix)  # Refined solution\n",
    "    mec_curr = MEC(SNV_matrix, hap_matrix)  # Current MEC\n",
    "\n",
    "    hap_matrix_new = deepcopy(hap_matrix)\n",
    "    while True:\n",
    "        mec_startiter = mec_curr\n",
    "        for j in range(np.shape(hap_matrix)[1]):\n",
    "            hap_matrix_new[:,j] = hap_matrix[:,j][::-1]  # Flip base\n",
    "            mec_new = MEC(SNV_matrix, hap_matrix_new)\n",
    "            if mec_new < mec_curr:  # Update refined solution\n",
    "                mec_curr = mec_new\n",
    "                hap_matrix_greedy[:,j] = hap_matrix[:,j][::-1]\n",
    "            else:  # Reverse base flip\n",
    "                hap_matrix_new[:,j] = hap_matrix[:,j]\n",
    "        if mec_curr == mec_startiter:  # Greedy refinement not improving MEC\n",
    "            return hap_matrix_greedy\n",
    "        elif verbose:\n",
    "            print(\"MEC improved from %i to %i\"%(mec_startiter, mec_curr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up dataloader and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outhead = 'cov20_hlen100'\n",
    "outhead = 'haptest'\n",
    "# datapath = 'Simulated_data/diploid/cov15/sample1/simu_erro1_K2_cov5'\\\n",
    "#             '_l5000_iter_1_SNV_matrix.txt'\n",
    "datapath = 'generate_data/' + outhead + '/' + outhead + '_SNV_matrix.txt'\n",
    "\n",
    "SNVdata = SNVMatrixDataset(datapath)\n",
    "SNV_matrix = np.loadtxt(datapath, dtype=int)\n",
    "SNV_matrix = SNV_matrix[np.sum(SNV_matrix != 0, axis=1) > 1]  # Removing uninformative reads\n",
    "nSNP = SNV_matrix.shape[1] # Number of SNVs\n",
    "num_read = len(SNVdata)  # Number of reads\n",
    "batch_size = int(np.ceil(num_read/20))\n",
    "d_model = 128  # Size of embeddings\n",
    "\n",
    "dataloader = DataLoader(SNVdata, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_file = \"Simulated_data/diploid/cov15/sample1/combined.fa\"\n",
    "# pos_file = \"Simulated_data/diploid/cov15/sample1/\"\\\n",
    "#             \"simu_erro1_K2_cov5_l5000_iter_1_SNV_pos.txt\"\n",
    "gt_file = 'generate_data/' + outhead + '/combined.fa'\n",
    "pos_file = 'generate_data/' + outhead + '/' + outhead + '_SNV_pos.txt'\n",
    "true_haplo = read_true_hap(gt_file, pos_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load autoencoder for read embeddings. If the weights aren't stored in savefile, train autoencoder for said embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [01:25<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "savefile=\"read_AE\"\n",
    "embedAE = learn_embed(SNVdata, num_epoch=100, embed_dim=d_model, savefile=savefile)\n",
    "\n",
    "# if path.isfile(savefile):\n",
    "#     embedAE = ReadAE(nSNP, latent_dim=d_model)\n",
    "#     embed_optimizer = optim.Adam(embedAE.parameters(), lr=1e-2)\n",
    "#     embedAE, embed_optimizer, _ = load_ckp(savefile, embedAE, embed_optimizer)\n",
    "# else:\n",
    "#     embedAE = learn_embed(SNVdata, num_epoch=100, embed_dim=d_model, savefile=savefile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up transformer with hyperparameters and training it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_xformer = CorrTransformer(d_model, d_model//2)  # Transformer\n",
    "num_epoch = 1000\n",
    "warmup_steps = 10  # Number of steps to linear increase learning rate\n",
    "\n",
    "# xform_optimizer = ScheduledOptim(\n",
    "#     optim.Adam(corr_xformer.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
    "#         lr_mul=0.1, d_model=d_model, n_warmup_steps=warmup_steps) # Optimizer with customized schedule\n",
    "xform_optimizer = optim.AdamW(corr_xformer.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xformer_loss(xformer_output: torch.Tensor, origin: torch.Tensor,\n",
    "                 Ws: torch.Tensor, Wmask: torch.Tensor,\n",
    "                 lambda_reg: float = 0.1) -> float:\n",
    "    \n",
    "    origin_main = origin.type(torch.FloatTensor)\n",
    "    obj_main = -1*torch.matmul(origin_main, torch.matmul(xformer_output, origin_main))\n",
    "    \n",
    "    origin_onehot = F.one_hot(origin + 1)\n",
    "    pair_mem = torch.matmul(origin_onehot, origin_onehot.transpose(0,1))\n",
    "    obj_cont = torch.sum((1-pair_mem)*xformer_output**2 + pair_mem*torch.clamp(1-xformer_output, min=0)**2)\n",
    "    \n",
    "    obj_reg = lambda_reg*torch.linalg.norm(xformer_output - Ws)**2\n",
    "    \n",
    "    res = obj_cont + obj_reg\n",
    "#     print('Clustering loss: %.3f, regularization: %.3f' %(obj_cont, obj_reg))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1]), array([155, 175]))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(F.one_hot(torch.from_numpy((hap_origin+1))),\n",
    "            F.one_hot(torch.from_numpy((hap_origin+1))).transpose(0,1)\n",
    "           )[0]\n",
    "np.unique(hap_origin, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "f_handler = logging.FileHandler('xformer_train.log')\n",
    "c_handler.setLevel(logging.WARNING)\n",
    "f_handler.setLevel(logging.INFO)\n",
    "f_handler.addFilter(MyFilter(logging.INFO))\n",
    "\n",
    "# Create formatters and add it to handlers\n",
    "c_format = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "f_format = logging.Formatter('%(message)s')\n",
    "c_handler.setFormatter(c_format)\n",
    "f_handler.setFormatter(f_format)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(c_handler)\n",
    "logger.addHandler(f_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 330/330 [00:01<00:00, 309.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1716)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xform_train_loss_arr = []\n",
    "mec = []\n",
    "cpr = []\n",
    "xformer_savefile = \"corr_xformer\"\n",
    "\n",
    "hap_origin = det_memhap(SNVdata, embedAE, corr_xformer)  # Initial haplotype memberships\n",
    "hap_matrix = origin2hap(SNV_matrix, (hap_origin.astype(int) + 1)/2) \n",
    "mec.append(MEC(SNV_matrix, hap_matrix))\n",
    "cpr.append(compute_cpr(hap_matrix, true_haplo))\n",
    "mec_min = np.inf\n",
    "cpr_max = 0\n",
    "\n",
    "num_reads = np.shape(SNV_matrix)[0]\n",
    "W_sim = np.zeros((num_reads, num_reads))\n",
    "W_dissim = np.zeros((num_reads, num_reads))\n",
    "W_mask = np.zeros((num_reads, num_reads), dtype=bool)\n",
    "\n",
    "# Computing similarity matrix for supervision\n",
    "for i, read_i in enumerate(tqdm(SNV_matrix)):\n",
    "    for j, read_j in enumerate(SNV_matrix):\n",
    "        if np.any((read_i != 0) & (read_j != 0)):  # Only if reads overlap\n",
    "            W_mask[i, j] = True\n",
    "            W_sim[i, j] = np.sum((read_i == read_j)[(read_i != 0) | (read_j != 0)])\n",
    "            W_dissim[i, j] = np.sum((read_i != read_j)[(read_i != 0) | (read_j != 0)])\n",
    "\n",
    "W_mask = torch.from_numpy(W_mask)\n",
    "W_sup = torch.from_numpy((W_sim - W_dissim)/(W_sim + W_dissim + 1e-10))\n",
    "print(torch.sum(W_mask)/torch.numel(W_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/1000, loss = 33561.61\n",
      "epoch : 2/1000, loss = 32324.61\n",
      "epoch : 3/1000, loss = 30409.71\n",
      "epoch : 4/1000, loss = 25811.44\n",
      "epoch : 5/1000, loss = 22581.64\n",
      "epoch : 6/1000, loss = 14156.05\n",
      "epoch : 7/1000, loss = 7932.55\n",
      "epoch : 8/1000, loss = 5216.04\n",
      "epoch : 9/1000, loss = 4711.19\n",
      "epoch : 10/1000, loss = 4570.51\n",
      "epoch : 11/1000, loss = 4348.67\n",
      "epoch : 12/1000, loss = 4473.71\n",
      "epoch : 13/1000, loss = 4600.86\n",
      "epoch : 14/1000, loss = 4613.14\n",
      "epoch : 15/1000, loss = 4439.92\n",
      "epoch : 16/1000, loss = 4780.43\n",
      "epoch : 17/1000, loss = 4466.41\n",
      "epoch : 18/1000, loss = 4528.83\n",
      "epoch : 19/1000, loss = 4860.09\n",
      "epoch : 20/1000, loss = 4649.39\n",
      "epoch : 21/1000, loss = 4546.64\n",
      "epoch : 22/1000, loss = 4676.86\n",
      "epoch : 23/1000, loss = 4315.31\n",
      "epoch : 24/1000, loss = 4516.15\n",
      "epoch : 25/1000, loss = 4213.12\n",
      "epoch : 26/1000, loss = 4300.06\n",
      "epoch : 27/1000, loss = 4157.58\n",
      "epoch : 28/1000, loss = 4399.95\n",
      "epoch : 29/1000, loss = 4279.98\n",
      "epoch : 30/1000, loss = 4575.22\n",
      "epoch : 31/1000, loss = 3973.95\n",
      "epoch : 32/1000, loss = 4563.60\n",
      "epoch : 33/1000, loss = 4572.74\n",
      "epoch : 34/1000, loss = 4515.03\n",
      "epoch : 35/1000, loss = 4004.79\n",
      "epoch : 36/1000, loss = 4509.07\n",
      "epoch : 37/1000, loss = 4214.56\n",
      "epoch : 38/1000, loss = 4295.83\n",
      "epoch : 39/1000, loss = 4450.56\n",
      "epoch : 40/1000, loss = 4240.63\n",
      "epoch : 41/1000, loss = 4124.27\n",
      "epoch : 42/1000, loss = 4282.21\n",
      "epoch : 43/1000, loss = 4086.66\n",
      "epoch : 44/1000, loss = 4451.04\n",
      "epoch : 45/1000, loss = 4156.54\n",
      "epoch : 46/1000, loss = 4331.86\n",
      "epoch : 47/1000, loss = 4311.97\n",
      "epoch : 48/1000, loss = 3927.95\n",
      "epoch : 49/1000, loss = 4293.65\n",
      "epoch : 50/1000, loss = 4378.29\n",
      "epoch : 51/1000, loss = 4380.88\n",
      "epoch : 52/1000, loss = 4463.41\n",
      "epoch : 53/1000, loss = 4316.98\n",
      "epoch : 54/1000, loss = 4311.53\n",
      "epoch : 55/1000, loss = 3953.99\n",
      "epoch : 56/1000, loss = 3979.84\n",
      "epoch : 57/1000, loss = 4158.45\n",
      "epoch : 58/1000, loss = 4339.94\n",
      "epoch : 59/1000, loss = 3984.85\n",
      "epoch : 60/1000, loss = 4045.11\n",
      "epoch : 61/1000, loss = 4212.67\n",
      "epoch : 62/1000, loss = 3977.57\n",
      "epoch : 63/1000, loss = 4160.36\n",
      "epoch : 64/1000, loss = 4234.22\n",
      "epoch : 65/1000, loss = 4323.96\n",
      "epoch : 66/1000, loss = 4006.09\n",
      "epoch : 67/1000, loss = 4342.69\n",
      "epoch : 68/1000, loss = 3944.19\n",
      "epoch : 69/1000, loss = 4650.47\n",
      "epoch : 70/1000, loss = 4210.03\n",
      "epoch : 71/1000, loss = 4132.31\n",
      "epoch : 72/1000, loss = 4139.06\n",
      "epoch : 73/1000, loss = 4217.35\n",
      "epoch : 74/1000, loss = 3776.93\n",
      "epoch : 75/1000, loss = 4119.54\n",
      "epoch : 76/1000, loss = 4046.29\n",
      "epoch : 77/1000, loss = 3972.98\n",
      "epoch : 78/1000, loss = 4080.72\n",
      "epoch : 79/1000, loss = 4125.52\n",
      "epoch : 80/1000, loss = 4208.98\n",
      "epoch : 81/1000, loss = 3781.81\n",
      "epoch : 82/1000, loss = 4045.49\n",
      "epoch : 83/1000, loss = 3960.77\n",
      "epoch : 84/1000, loss = 4151.08\n",
      "epoch : 85/1000, loss = 4248.56\n",
      "epoch : 86/1000, loss = 4374.46\n",
      "epoch : 87/1000, loss = 4173.20\n",
      "epoch : 88/1000, loss = 4010.51\n",
      "epoch : 89/1000, loss = 4083.45\n",
      "epoch : 90/1000, loss = 4128.64\n",
      "epoch : 91/1000, loss = 4333.54\n",
      "epoch : 92/1000, loss = 3847.43\n",
      "epoch : 93/1000, loss = 4265.13\n",
      "epoch : 94/1000, loss = 3847.80\n",
      "epoch : 95/1000, loss = 4253.35\n",
      "epoch : 96/1000, loss = 4102.18\n",
      "epoch : 97/1000, loss = 4293.61\n",
      "epoch : 98/1000, loss = 4033.13\n",
      "epoch : 99/1000, loss = 4193.42\n",
      "epoch : 100/1000, loss = 3934.82\n",
      "epoch : 101/1000, loss = 3745.60\n",
      "epoch : 102/1000, loss = 4265.09\n",
      "epoch : 103/1000, loss = 3973.35\n",
      "epoch : 104/1000, loss = 3875.37\n",
      "epoch : 105/1000, loss = 4596.72\n",
      "epoch : 106/1000, loss = 4328.60\n",
      "epoch : 107/1000, loss = 4243.48\n",
      "epoch : 108/1000, loss = 3775.54\n",
      "epoch : 109/1000, loss = 4183.00\n",
      "epoch : 110/1000, loss = 4087.06\n",
      "epoch : 111/1000, loss = 4381.29\n",
      "epoch : 112/1000, loss = 4166.27\n",
      "epoch : 113/1000, loss = 3901.58\n",
      "epoch : 114/1000, loss = 4298.36\n",
      "epoch : 115/1000, loss = 4373.75\n",
      "epoch : 116/1000, loss = 4155.19\n",
      "epoch : 117/1000, loss = 3770.88\n",
      "epoch : 118/1000, loss = 3949.84\n",
      "epoch : 119/1000, loss = 4058.08\n",
      "epoch : 120/1000, loss = 4012.91\n",
      "epoch : 121/1000, loss = 4108.24\n",
      "epoch : 122/1000, loss = 4263.92\n",
      "epoch : 123/1000, loss = 4152.15\n",
      "epoch : 124/1000, loss = 4196.75\n",
      "epoch : 125/1000, loss = 4288.46\n",
      "epoch : 126/1000, loss = 4228.06\n",
      "epoch : 127/1000, loss = 4269.42\n",
      "epoch : 128/1000, loss = 4195.42\n",
      "epoch : 129/1000, loss = 4011.42\n",
      "epoch : 130/1000, loss = 3800.15\n",
      "epoch : 131/1000, loss = 4014.32\n",
      "epoch : 132/1000, loss = 4218.26\n",
      "epoch : 133/1000, loss = 4062.52\n",
      "epoch : 134/1000, loss = 3880.50\n",
      "epoch : 135/1000, loss = 3952.62\n",
      "epoch : 136/1000, loss = 4080.01\n",
      "epoch : 137/1000, loss = 3828.86\n",
      "epoch : 138/1000, loss = 3870.13\n",
      "epoch : 139/1000, loss = 3769.73\n",
      "epoch : 140/1000, loss = 3796.86\n",
      "epoch : 141/1000, loss = 4059.11\n",
      "epoch : 142/1000, loss = 3976.37\n",
      "epoch : 143/1000, loss = 4035.49\n",
      "epoch : 144/1000, loss = 3986.76\n",
      "epoch : 145/1000, loss = 3856.51\n",
      "epoch : 146/1000, loss = 4076.42\n",
      "epoch : 147/1000, loss = 4029.62\n",
      "epoch : 148/1000, loss = 3628.15\n",
      "epoch : 149/1000, loss = 3970.26\n",
      "epoch : 150/1000, loss = 4092.67\n",
      "epoch : 151/1000, loss = 4007.37\n",
      "epoch : 152/1000, loss = 4147.76\n",
      "epoch : 153/1000, loss = 3969.55\n",
      "epoch : 154/1000, loss = 3875.63\n",
      "epoch : 155/1000, loss = 4091.53\n",
      "epoch : 156/1000, loss = 4362.89\n",
      "epoch : 157/1000, loss = 3538.98\n",
      "epoch : 158/1000, loss = 3979.76\n",
      "epoch : 159/1000, loss = 3970.04\n",
      "epoch : 160/1000, loss = 3871.67\n",
      "epoch : 161/1000, loss = 3707.40\n",
      "epoch : 162/1000, loss = 4194.14\n",
      "epoch : 163/1000, loss = 4029.50\n",
      "epoch : 164/1000, loss = 4122.55\n",
      "epoch : 165/1000, loss = 4044.42\n",
      "epoch : 166/1000, loss = 3866.41\n",
      "epoch : 167/1000, loss = 4186.85\n",
      "epoch : 168/1000, loss = 3804.81\n",
      "epoch : 169/1000, loss = 3998.89\n",
      "epoch : 170/1000, loss = 4218.05\n",
      "epoch : 171/1000, loss = 3776.22\n",
      "epoch : 172/1000, loss = 3750.40\n",
      "epoch : 173/1000, loss = 4041.93\n",
      "epoch : 174/1000, loss = 4201.54\n",
      "epoch : 175/1000, loss = 3985.84\n",
      "epoch : 176/1000, loss = 3870.84\n",
      "epoch : 177/1000, loss = 3817.75\n",
      "epoch : 178/1000, loss = 3832.22\n",
      "epoch : 179/1000, loss = 3962.62\n",
      "epoch : 180/1000, loss = 3815.07\n",
      "epoch : 181/1000, loss = 3898.59\n",
      "epoch : 182/1000, loss = 4032.97\n",
      "epoch : 183/1000, loss = 3798.99\n",
      "epoch : 184/1000, loss = 4082.62\n",
      "epoch : 185/1000, loss = 3716.05\n",
      "epoch : 186/1000, loss = 3832.64\n",
      "epoch : 187/1000, loss = 3575.23\n",
      "epoch : 188/1000, loss = 3915.65\n",
      "epoch : 189/1000, loss = 4194.56\n",
      "epoch : 190/1000, loss = 4076.64\n",
      "epoch : 191/1000, loss = 3982.48\n",
      "epoch : 192/1000, loss = 4702.01\n",
      "epoch : 193/1000, loss = 3814.33\n",
      "epoch : 194/1000, loss = 3885.81\n",
      "epoch : 195/1000, loss = 4012.85\n",
      "epoch : 196/1000, loss = 3807.31\n",
      "epoch : 197/1000, loss = 4019.14\n",
      "epoch : 198/1000, loss = 4096.08\n",
      "epoch : 199/1000, loss = 3857.39\n",
      "epoch : 200/1000, loss = 3967.19\n",
      "epoch : 201/1000, loss = 3909.43\n",
      "epoch : 202/1000, loss = 3894.08\n",
      "epoch : 203/1000, loss = 4089.53\n",
      "epoch : 204/1000, loss = 3885.96\n",
      "epoch : 205/1000, loss = 3782.22\n",
      "epoch : 206/1000, loss = 4064.22\n",
      "epoch : 207/1000, loss = 4047.93\n",
      "epoch : 208/1000, loss = 3885.42\n",
      "epoch : 209/1000, loss = 3852.43\n",
      "epoch : 210/1000, loss = 4027.61\n",
      "epoch : 211/1000, loss = 3926.35\n",
      "epoch : 212/1000, loss = 3785.01\n",
      "epoch : 213/1000, loss = 4164.23\n",
      "epoch : 214/1000, loss = 3934.26\n",
      "epoch : 215/1000, loss = 3957.22\n",
      "epoch : 216/1000, loss = 3962.88\n",
      "epoch : 217/1000, loss = 3741.26\n",
      "epoch : 218/1000, loss = 3847.33\n",
      "epoch : 219/1000, loss = 3983.83\n",
      "epoch : 220/1000, loss = 4173.41\n",
      "epoch : 221/1000, loss = 3809.98\n",
      "epoch : 222/1000, loss = 4049.17\n",
      "epoch : 223/1000, loss = 3857.85\n",
      "epoch : 224/1000, loss = 3971.43\n",
      "epoch : 225/1000, loss = 4015.31\n",
      "epoch : 226/1000, loss = 3632.06\n",
      "epoch : 227/1000, loss = 3783.82\n",
      "epoch : 228/1000, loss = 4116.17\n",
      "epoch : 229/1000, loss = 4342.44\n",
      "epoch : 230/1000, loss = 4054.18\n",
      "epoch : 231/1000, loss = 4090.32\n",
      "epoch : 232/1000, loss = 4049.56\n",
      "epoch : 233/1000, loss = 3784.85\n",
      "epoch : 234/1000, loss = 3932.15\n",
      "epoch : 235/1000, loss = 3856.42\n",
      "epoch : 236/1000, loss = 3767.64\n",
      "epoch : 237/1000, loss = 3698.64\n",
      "epoch : 238/1000, loss = 4029.73\n",
      "epoch : 239/1000, loss = 3908.82\n",
      "epoch : 240/1000, loss = 3951.22\n",
      "epoch : 241/1000, loss = 4104.48\n",
      "epoch : 242/1000, loss = 4062.46\n",
      "epoch : 243/1000, loss = 4112.58\n",
      "epoch : 244/1000, loss = 4106.95\n",
      "epoch : 245/1000, loss = 3724.40\n",
      "epoch : 246/1000, loss = 3973.83\n",
      "epoch : 247/1000, loss = 4014.62\n",
      "epoch : 248/1000, loss = 3999.62\n",
      "epoch : 249/1000, loss = 4075.76\n",
      "epoch : 250/1000, loss = 4094.03\n",
      "epoch : 251/1000, loss = 4050.84\n",
      "epoch : 252/1000, loss = 3787.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 253/1000, loss = 4078.86\n",
      "epoch : 254/1000, loss = 3756.55\n",
      "epoch : 255/1000, loss = 3902.07\n",
      "epoch : 256/1000, loss = 3897.24\n",
      "epoch : 257/1000, loss = 3996.02\n",
      "epoch : 258/1000, loss = 4156.72\n",
      "epoch : 259/1000, loss = 3784.35\n",
      "epoch : 260/1000, loss = 3791.61\n",
      "epoch : 261/1000, loss = 4133.63\n",
      "epoch : 262/1000, loss = 3771.06\n",
      "epoch : 263/1000, loss = 3795.38\n",
      "epoch : 264/1000, loss = 4227.80\n",
      "epoch : 265/1000, loss = 3805.22\n",
      "epoch : 266/1000, loss = 3946.03\n",
      "epoch : 267/1000, loss = 3910.20\n",
      "epoch : 268/1000, loss = 4049.23\n",
      "epoch : 269/1000, loss = 4028.20\n",
      "epoch : 270/1000, loss = 3867.65\n",
      "epoch : 271/1000, loss = 4197.78\n",
      "epoch : 272/1000, loss = 4007.80\n",
      "epoch : 273/1000, loss = 3879.45\n",
      "epoch : 274/1000, loss = 4073.32\n",
      "epoch : 275/1000, loss = 4560.69\n",
      "epoch : 276/1000, loss = 3958.91\n",
      "epoch : 277/1000, loss = 3965.23\n",
      "epoch : 278/1000, loss = 3919.78\n",
      "epoch : 279/1000, loss = 4150.37\n",
      "epoch : 280/1000, loss = 4134.09\n",
      "epoch : 281/1000, loss = 3873.95\n",
      "epoch : 282/1000, loss = 3656.79\n",
      "epoch : 283/1000, loss = 3782.66\n",
      "epoch : 284/1000, loss = 3753.30\n",
      "epoch : 285/1000, loss = 3791.79\n",
      "epoch : 286/1000, loss = 3623.97\n",
      "epoch : 287/1000, loss = 4123.17\n",
      "epoch : 288/1000, loss = 3911.34\n",
      "epoch : 289/1000, loss = 3815.55\n",
      "epoch : 290/1000, loss = 3640.71\n",
      "epoch : 291/1000, loss = 3834.57\n",
      "epoch : 292/1000, loss = 3887.11\n",
      "epoch : 293/1000, loss = 3862.48\n",
      "epoch : 294/1000, loss = 3756.37\n",
      "epoch : 295/1000, loss = 3516.28\n",
      "epoch : 296/1000, loss = 3949.86\n",
      "epoch : 297/1000, loss = 4250.85\n",
      "epoch : 298/1000, loss = 3962.45\n",
      "epoch : 299/1000, loss = 3976.03\n",
      "epoch : 300/1000, loss = 3717.01\n",
      "epoch : 301/1000, loss = 4114.28\n",
      "epoch : 302/1000, loss = 4025.37\n",
      "epoch : 303/1000, loss = 3952.18\n",
      "epoch : 304/1000, loss = 4007.41\n",
      "epoch : 305/1000, loss = 3879.40\n",
      "epoch : 306/1000, loss = 4078.81\n",
      "epoch : 307/1000, loss = 4034.34\n",
      "epoch : 308/1000, loss = 3954.56\n",
      "epoch : 309/1000, loss = 4097.46\n",
      "epoch : 310/1000, loss = 3640.48\n",
      "epoch : 311/1000, loss = 3834.81\n",
      "epoch : 312/1000, loss = 4024.45\n",
      "epoch : 313/1000, loss = 3997.58\n",
      "epoch : 314/1000, loss = 4180.27\n",
      "epoch : 315/1000, loss = 4205.27\n",
      "epoch : 316/1000, loss = 4261.58\n",
      "epoch : 317/1000, loss = 3939.75\n",
      "epoch : 318/1000, loss = 3937.94\n",
      "epoch : 319/1000, loss = 3617.35\n",
      "epoch : 320/1000, loss = 3862.89\n",
      "epoch : 321/1000, loss = 3963.93\n",
      "epoch : 322/1000, loss = 4025.05\n",
      "epoch : 323/1000, loss = 3576.78\n",
      "epoch : 324/1000, loss = 3884.00\n",
      "epoch : 325/1000, loss = 4107.02\n",
      "epoch : 326/1000, loss = 4016.14\n",
      "epoch : 327/1000, loss = 3606.34\n",
      "epoch : 328/1000, loss = 3885.88\n",
      "epoch : 329/1000, loss = 3936.42\n",
      "epoch : 330/1000, loss = 3933.17\n",
      "epoch : 331/1000, loss = 3832.24\n",
      "epoch : 332/1000, loss = 4156.09\n",
      "epoch : 333/1000, loss = 3932.89\n",
      "epoch : 334/1000, loss = 3982.32\n",
      "epoch : 335/1000, loss = 4087.18\n",
      "epoch : 336/1000, loss = 3742.98\n",
      "epoch : 337/1000, loss = 4030.73\n",
      "epoch : 338/1000, loss = 4066.63\n",
      "epoch : 339/1000, loss = 3894.27\n",
      "epoch : 340/1000, loss = 3862.41\n",
      "epoch : 341/1000, loss = 3938.20\n",
      "epoch : 342/1000, loss = 3904.53\n",
      "epoch : 343/1000, loss = 3928.36\n",
      "epoch : 344/1000, loss = 3655.69\n",
      "epoch : 345/1000, loss = 4054.47\n",
      "epoch : 346/1000, loss = 3749.54\n",
      "epoch : 347/1000, loss = 4116.41\n",
      "epoch : 348/1000, loss = 3888.45\n",
      "epoch : 349/1000, loss = 3689.73\n",
      "epoch : 350/1000, loss = 4224.06\n",
      "epoch : 351/1000, loss = 3948.79\n",
      "epoch : 352/1000, loss = 3850.66\n",
      "epoch : 353/1000, loss = 3978.81\n",
      "epoch : 354/1000, loss = 3918.81\n",
      "epoch : 355/1000, loss = 3927.09\n",
      "epoch : 356/1000, loss = 3910.30\n",
      "epoch : 357/1000, loss = 3856.31\n",
      "epoch : 358/1000, loss = 3941.51\n",
      "epoch : 359/1000, loss = 3791.05\n",
      "epoch : 360/1000, loss = 4072.27\n",
      "epoch : 361/1000, loss = 3882.23\n",
      "epoch : 362/1000, loss = 3710.40\n",
      "epoch : 363/1000, loss = 3797.25\n",
      "epoch : 364/1000, loss = 3979.17\n",
      "epoch : 365/1000, loss = 4117.41\n",
      "epoch : 366/1000, loss = 4138.70\n",
      "epoch : 367/1000, loss = 4200.16\n",
      "epoch : 368/1000, loss = 4200.06\n",
      "epoch : 369/1000, loss = 3929.42\n",
      "epoch : 370/1000, loss = 3748.93\n",
      "epoch : 371/1000, loss = 4222.74\n",
      "epoch : 372/1000, loss = 3832.78\n",
      "epoch : 373/1000, loss = 4198.96\n",
      "epoch : 374/1000, loss = 3824.72\n",
      "epoch : 375/1000, loss = 3723.60\n",
      "epoch : 376/1000, loss = 3755.47\n",
      "epoch : 377/1000, loss = 3966.69\n",
      "epoch : 378/1000, loss = 3618.83\n",
      "epoch : 379/1000, loss = 3914.78\n",
      "epoch : 380/1000, loss = 4068.65\n",
      "epoch : 381/1000, loss = 3780.51\n",
      "epoch : 382/1000, loss = 3948.98\n",
      "epoch : 383/1000, loss = 4130.51\n",
      "epoch : 384/1000, loss = 3635.62\n",
      "epoch : 385/1000, loss = 4050.22\n",
      "epoch : 386/1000, loss = 3886.05\n",
      "epoch : 387/1000, loss = 4091.87\n",
      "epoch : 388/1000, loss = 3862.19\n",
      "epoch : 389/1000, loss = 3989.66\n",
      "epoch : 390/1000, loss = 3839.79\n",
      "epoch : 391/1000, loss = 4086.58\n",
      "epoch : 392/1000, loss = 3860.04\n",
      "epoch : 393/1000, loss = 3710.30\n",
      "epoch : 394/1000, loss = 3816.36\n",
      "epoch : 395/1000, loss = 3953.86\n",
      "epoch : 396/1000, loss = 3905.63\n",
      "epoch : 397/1000, loss = 3865.73\n",
      "epoch : 398/1000, loss = 4209.95\n",
      "epoch : 399/1000, loss = 3891.13\n",
      "epoch : 400/1000, loss = 4040.27\n",
      "epoch : 401/1000, loss = 3783.41\n",
      "epoch : 402/1000, loss = 4081.23\n",
      "epoch : 403/1000, loss = 3694.87\n",
      "epoch : 404/1000, loss = 3908.53\n",
      "epoch : 405/1000, loss = 3613.75\n",
      "epoch : 406/1000, loss = 3792.82\n",
      "epoch : 407/1000, loss = 4175.17\n",
      "epoch : 408/1000, loss = 4036.92\n",
      "epoch : 409/1000, loss = 3849.45\n",
      "epoch : 410/1000, loss = 4074.83\n",
      "epoch : 411/1000, loss = 3870.86\n",
      "epoch : 412/1000, loss = 3894.37\n",
      "epoch : 413/1000, loss = 3932.64\n",
      "epoch : 414/1000, loss = 3836.50\n",
      "epoch : 415/1000, loss = 3798.19\n",
      "epoch : 416/1000, loss = 3644.60\n",
      "epoch : 417/1000, loss = 4002.81\n",
      "epoch : 418/1000, loss = 3694.28\n",
      "epoch : 419/1000, loss = 3873.83\n",
      "epoch : 420/1000, loss = 3832.80\n",
      "epoch : 421/1000, loss = 3924.28\n",
      "epoch : 422/1000, loss = 3939.19\n",
      "epoch : 423/1000, loss = 3863.68\n",
      "epoch : 424/1000, loss = 3701.91\n",
      "epoch : 425/1000, loss = 4031.00\n",
      "epoch : 426/1000, loss = 3653.47\n",
      "epoch : 427/1000, loss = 4009.79\n",
      "epoch : 428/1000, loss = 3943.37\n",
      "epoch : 429/1000, loss = 3816.95\n",
      "epoch : 430/1000, loss = 3980.20\n",
      "epoch : 431/1000, loss = 3869.50\n",
      "epoch : 432/1000, loss = 4018.45\n",
      "epoch : 433/1000, loss = 3861.72\n",
      "epoch : 434/1000, loss = 3755.95\n",
      "epoch : 435/1000, loss = 4108.58\n",
      "epoch : 436/1000, loss = 3833.00\n",
      "epoch : 437/1000, loss = 3837.59\n",
      "epoch : 438/1000, loss = 4096.46\n",
      "epoch : 439/1000, loss = 4084.52\n",
      "epoch : 440/1000, loss = 3662.17\n",
      "epoch : 441/1000, loss = 3968.31\n",
      "epoch : 442/1000, loss = 3762.80\n",
      "epoch : 443/1000, loss = 3707.43\n",
      "epoch : 444/1000, loss = 3671.11\n",
      "epoch : 445/1000, loss = 3883.77\n",
      "epoch : 446/1000, loss = 3952.85\n",
      "epoch : 447/1000, loss = 3843.02\n",
      "epoch : 448/1000, loss = 3793.60\n",
      "epoch : 449/1000, loss = 3918.27\n",
      "epoch : 450/1000, loss = 3912.28\n",
      "epoch : 451/1000, loss = 3662.49\n",
      "epoch : 452/1000, loss = 3844.08\n",
      "epoch : 453/1000, loss = 3960.32\n",
      "epoch : 454/1000, loss = 4118.54\n",
      "epoch : 455/1000, loss = 3929.37\n",
      "epoch : 456/1000, loss = 3763.35\n",
      "epoch : 457/1000, loss = 3968.78\n",
      "epoch : 458/1000, loss = 3890.54\n",
      "epoch : 459/1000, loss = 3849.12\n",
      "epoch : 460/1000, loss = 3825.47\n",
      "epoch : 461/1000, loss = 3672.63\n",
      "epoch : 462/1000, loss = 3823.43\n",
      "epoch : 463/1000, loss = 3991.02\n",
      "epoch : 464/1000, loss = 4097.26\n",
      "epoch : 465/1000, loss = 3918.77\n",
      "epoch : 466/1000, loss = 3923.01\n",
      "epoch : 467/1000, loss = 3742.03\n",
      "epoch : 468/1000, loss = 3952.22\n",
      "epoch : 469/1000, loss = 3826.88\n",
      "epoch : 470/1000, loss = 3636.66\n",
      "epoch : 471/1000, loss = 3879.01\n",
      "epoch : 472/1000, loss = 4033.76\n",
      "epoch : 473/1000, loss = 4022.08\n",
      "epoch : 474/1000, loss = 3808.60\n",
      "epoch : 475/1000, loss = 3579.89\n",
      "epoch : 476/1000, loss = 3757.07\n",
      "epoch : 477/1000, loss = 3752.01\n",
      "epoch : 478/1000, loss = 4201.25\n",
      "epoch : 479/1000, loss = 3826.42\n",
      "epoch : 480/1000, loss = 3734.80\n",
      "epoch : 481/1000, loss = 3917.92\n",
      "epoch : 482/1000, loss = 4058.66\n",
      "epoch : 483/1000, loss = 4199.40\n",
      "epoch : 484/1000, loss = 3649.16\n",
      "epoch : 485/1000, loss = 3629.12\n",
      "epoch : 486/1000, loss = 3536.70\n",
      "epoch : 487/1000, loss = 3750.01\n",
      "epoch : 488/1000, loss = 3975.06\n",
      "epoch : 489/1000, loss = 3835.98\n",
      "epoch : 490/1000, loss = 4035.27\n",
      "epoch : 491/1000, loss = 3639.21\n",
      "epoch : 492/1000, loss = 3812.91\n",
      "epoch : 493/1000, loss = 4010.23\n",
      "epoch : 494/1000, loss = 3947.63\n",
      "epoch : 495/1000, loss = 3760.34\n",
      "epoch : 496/1000, loss = 3927.96\n",
      "epoch : 497/1000, loss = 3816.46\n",
      "epoch : 498/1000, loss = 3866.60\n",
      "epoch : 499/1000, loss = 4050.32\n",
      "epoch : 500/1000, loss = 4136.60\n",
      "epoch : 501/1000, loss = 3841.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 502/1000, loss = 4119.30\n",
      "epoch : 503/1000, loss = 3900.40\n",
      "epoch : 504/1000, loss = 3994.67\n",
      "epoch : 505/1000, loss = 3965.31\n",
      "epoch : 506/1000, loss = 3661.45\n",
      "epoch : 507/1000, loss = 4040.86\n",
      "epoch : 508/1000, loss = 3696.71\n",
      "epoch : 509/1000, loss = 4062.41\n",
      "epoch : 510/1000, loss = 3889.21\n",
      "epoch : 511/1000, loss = 3753.71\n",
      "epoch : 512/1000, loss = 3991.87\n",
      "epoch : 513/1000, loss = 3919.07\n",
      "epoch : 514/1000, loss = 3707.26\n",
      "epoch : 515/1000, loss = 3867.37\n",
      "epoch : 516/1000, loss = 3900.10\n",
      "epoch : 517/1000, loss = 3803.17\n",
      "epoch : 518/1000, loss = 3797.12\n",
      "epoch : 519/1000, loss = 3818.64\n",
      "epoch : 520/1000, loss = 3971.13\n",
      "epoch : 521/1000, loss = 3763.85\n",
      "epoch : 522/1000, loss = 3846.25\n",
      "epoch : 523/1000, loss = 3935.89\n",
      "epoch : 524/1000, loss = 3684.95\n",
      "epoch : 525/1000, loss = 4163.35\n",
      "epoch : 526/1000, loss = 4222.98\n",
      "epoch : 527/1000, loss = 3926.59\n",
      "epoch : 528/1000, loss = 3919.14\n",
      "epoch : 529/1000, loss = 3899.02\n",
      "epoch : 530/1000, loss = 3842.93\n",
      "epoch : 531/1000, loss = 3908.03\n",
      "epoch : 532/1000, loss = 3699.63\n",
      "epoch : 533/1000, loss = 3788.04\n",
      "epoch : 534/1000, loss = 3797.40\n",
      "epoch : 535/1000, loss = 3879.39\n",
      "epoch : 536/1000, loss = 3801.00\n",
      "epoch : 537/1000, loss = 3738.34\n",
      "epoch : 538/1000, loss = 3796.97\n",
      "epoch : 539/1000, loss = 3934.11\n",
      "epoch : 540/1000, loss = 4224.52\n",
      "epoch : 541/1000, loss = 4148.80\n",
      "epoch : 542/1000, loss = 4181.67\n",
      "epoch : 543/1000, loss = 3765.93\n",
      "epoch : 544/1000, loss = 4168.50\n",
      "epoch : 545/1000, loss = 3544.08\n",
      "epoch : 546/1000, loss = 3825.67\n",
      "epoch : 547/1000, loss = 3925.10\n",
      "epoch : 548/1000, loss = 3863.63\n",
      "epoch : 549/1000, loss = 3837.26\n",
      "epoch : 550/1000, loss = 3891.10\n",
      "epoch : 551/1000, loss = 4134.40\n",
      "epoch : 552/1000, loss = 4090.39\n",
      "epoch : 553/1000, loss = 3820.72\n",
      "epoch : 554/1000, loss = 3844.29\n",
      "epoch : 555/1000, loss = 3839.34\n",
      "epoch : 556/1000, loss = 3843.56\n",
      "epoch : 557/1000, loss = 3972.23\n",
      "epoch : 558/1000, loss = 3979.07\n",
      "epoch : 559/1000, loss = 3531.48\n",
      "epoch : 560/1000, loss = 3896.16\n",
      "epoch : 561/1000, loss = 4178.57\n",
      "epoch : 562/1000, loss = 3920.38\n",
      "epoch : 563/1000, loss = 3703.98\n",
      "epoch : 564/1000, loss = 3500.81\n",
      "epoch : 565/1000, loss = 3912.62\n",
      "epoch : 566/1000, loss = 4017.88\n",
      "epoch : 567/1000, loss = 3796.75\n",
      "epoch : 568/1000, loss = 3958.85\n",
      "epoch : 569/1000, loss = 3940.95\n",
      "epoch : 570/1000, loss = 3886.28\n",
      "epoch : 571/1000, loss = 3959.69\n",
      "epoch : 572/1000, loss = 3849.79\n",
      "epoch : 573/1000, loss = 3918.04\n",
      "epoch : 574/1000, loss = 3842.35\n",
      "epoch : 575/1000, loss = 3988.01\n",
      "epoch : 576/1000, loss = 4067.51\n",
      "epoch : 577/1000, loss = 3852.65\n",
      "epoch : 578/1000, loss = 3970.50\n",
      "epoch : 579/1000, loss = 4182.01\n",
      "epoch : 580/1000, loss = 4154.29\n",
      "epoch : 581/1000, loss = 3786.72\n",
      "epoch : 582/1000, loss = 3942.46\n",
      "epoch : 583/1000, loss = 4008.23\n",
      "epoch : 584/1000, loss = 3638.86\n",
      "epoch : 585/1000, loss = 3727.47\n",
      "epoch : 586/1000, loss = 3749.27\n",
      "epoch : 587/1000, loss = 3614.25\n",
      "epoch : 588/1000, loss = 3865.76\n",
      "epoch : 589/1000, loss = 3905.13\n",
      "epoch : 590/1000, loss = 4074.95\n",
      "epoch : 591/1000, loss = 3566.83\n",
      "epoch : 592/1000, loss = 3679.26\n",
      "epoch : 593/1000, loss = 3856.58\n",
      "epoch : 594/1000, loss = 3741.64\n",
      "epoch : 595/1000, loss = 3634.64\n",
      "epoch : 596/1000, loss = 3930.60\n",
      "epoch : 597/1000, loss = 3835.35\n",
      "epoch : 598/1000, loss = 4400.35\n",
      "epoch : 599/1000, loss = 3842.20\n",
      "epoch : 600/1000, loss = 3796.70\n",
      "epoch : 601/1000, loss = 4016.54\n",
      "epoch : 602/1000, loss = 3644.94\n",
      "epoch : 603/1000, loss = 3957.88\n",
      "epoch : 604/1000, loss = 3985.39\n",
      "epoch : 605/1000, loss = 3878.32\n",
      "epoch : 606/1000, loss = 4041.11\n",
      "epoch : 607/1000, loss = 3556.25\n",
      "epoch : 608/1000, loss = 4008.56\n",
      "epoch : 609/1000, loss = 3866.87\n",
      "epoch : 610/1000, loss = 3882.23\n",
      "epoch : 611/1000, loss = 3861.60\n",
      "epoch : 612/1000, loss = 4120.52\n",
      "epoch : 613/1000, loss = 3727.01\n",
      "epoch : 614/1000, loss = 3988.44\n",
      "epoch : 615/1000, loss = 3808.39\n",
      "epoch : 616/1000, loss = 3801.30\n",
      "epoch : 617/1000, loss = 3811.73\n",
      "epoch : 618/1000, loss = 4363.46\n",
      "epoch : 619/1000, loss = 3801.35\n",
      "epoch : 620/1000, loss = 4013.84\n",
      "epoch : 621/1000, loss = 3720.18\n",
      "epoch : 622/1000, loss = 3992.66\n",
      "epoch : 623/1000, loss = 4096.58\n",
      "epoch : 624/1000, loss = 3723.89\n",
      "epoch : 625/1000, loss = 4079.40\n",
      "epoch : 626/1000, loss = 3826.89\n",
      "epoch : 627/1000, loss = 3919.88\n",
      "epoch : 628/1000, loss = 3596.09\n",
      "epoch : 629/1000, loss = 3712.84\n",
      "epoch : 630/1000, loss = 3543.55\n",
      "epoch : 631/1000, loss = 3604.58\n",
      "epoch : 632/1000, loss = 3730.80\n",
      "epoch : 633/1000, loss = 3603.91\n",
      "epoch : 634/1000, loss = 3929.38\n",
      "epoch : 635/1000, loss = 3912.91\n",
      "epoch : 636/1000, loss = 3698.76\n",
      "epoch : 637/1000, loss = 3796.52\n",
      "epoch : 638/1000, loss = 3766.79\n",
      "epoch : 639/1000, loss = 3959.12\n",
      "epoch : 640/1000, loss = 3835.18\n",
      "epoch : 641/1000, loss = 3813.20\n",
      "epoch : 642/1000, loss = 3939.61\n",
      "epoch : 643/1000, loss = 4137.04\n",
      "epoch : 644/1000, loss = 3976.55\n",
      "epoch : 645/1000, loss = 3555.04\n",
      "epoch : 646/1000, loss = 3766.79\n",
      "epoch : 647/1000, loss = 3916.86\n",
      "epoch : 648/1000, loss = 3872.75\n",
      "epoch : 649/1000, loss = 3960.01\n",
      "epoch : 650/1000, loss = 3810.99\n",
      "epoch : 651/1000, loss = 3871.93\n",
      "epoch : 652/1000, loss = 3933.93\n",
      "epoch : 653/1000, loss = 3768.63\n",
      "epoch : 654/1000, loss = 3608.49\n",
      "epoch : 655/1000, loss = 3821.97\n",
      "epoch : 656/1000, loss = 3852.31\n",
      "epoch : 657/1000, loss = 3720.55\n",
      "epoch : 658/1000, loss = 3830.86\n",
      "epoch : 659/1000, loss = 3692.36\n",
      "epoch : 660/1000, loss = 3695.65\n",
      "epoch : 661/1000, loss = 4109.08\n",
      "epoch : 662/1000, loss = 3718.17\n",
      "epoch : 663/1000, loss = 4230.90\n",
      "epoch : 664/1000, loss = 3999.79\n",
      "epoch : 665/1000, loss = 3800.88\n",
      "epoch : 666/1000, loss = 3835.10\n",
      "epoch : 667/1000, loss = 4005.97\n",
      "epoch : 668/1000, loss = 3617.48\n",
      "epoch : 669/1000, loss = 3824.44\n",
      "epoch : 670/1000, loss = 3908.37\n",
      "epoch : 671/1000, loss = 3768.35\n",
      "epoch : 672/1000, loss = 3806.26\n",
      "epoch : 673/1000, loss = 3800.99\n",
      "epoch : 674/1000, loss = 4037.79\n",
      "epoch : 675/1000, loss = 4064.13\n",
      "epoch : 676/1000, loss = 3757.42\n",
      "epoch : 677/1000, loss = 3824.39\n",
      "epoch : 678/1000, loss = 4072.30\n",
      "epoch : 679/1000, loss = 3598.14\n",
      "epoch : 680/1000, loss = 3704.63\n",
      "epoch : 681/1000, loss = 3894.69\n",
      "epoch : 682/1000, loss = 3951.58\n",
      "epoch : 683/1000, loss = 3828.09\n",
      "epoch : 684/1000, loss = 3728.73\n",
      "epoch : 685/1000, loss = 3795.30\n",
      "epoch : 686/1000, loss = 3943.63\n",
      "epoch : 687/1000, loss = 3800.05\n",
      "epoch : 688/1000, loss = 3807.15\n",
      "epoch : 689/1000, loss = 3707.29\n",
      "epoch : 690/1000, loss = 4023.33\n",
      "epoch : 691/1000, loss = 3696.64\n",
      "epoch : 692/1000, loss = 3981.42\n",
      "epoch : 693/1000, loss = 3925.75\n",
      "epoch : 694/1000, loss = 3524.35\n",
      "epoch : 695/1000, loss = 4021.59\n",
      "epoch : 696/1000, loss = 3956.54\n",
      "epoch : 697/1000, loss = 3911.73\n",
      "epoch : 698/1000, loss = 3915.85\n",
      "epoch : 699/1000, loss = 3625.62\n",
      "epoch : 700/1000, loss = 3972.55\n",
      "epoch : 701/1000, loss = 3881.92\n",
      "epoch : 702/1000, loss = 4011.58\n",
      "epoch : 703/1000, loss = 3942.25\n",
      "epoch : 704/1000, loss = 3634.17\n",
      "epoch : 705/1000, loss = 3739.72\n",
      "epoch : 706/1000, loss = 3816.23\n",
      "epoch : 707/1000, loss = 4057.38\n",
      "epoch : 708/1000, loss = 3765.30\n",
      "epoch : 709/1000, loss = 3880.91\n",
      "epoch : 710/1000, loss = 3900.11\n",
      "epoch : 711/1000, loss = 3872.62\n",
      "epoch : 712/1000, loss = 3981.87\n",
      "epoch : 713/1000, loss = 3534.51\n",
      "epoch : 714/1000, loss = 3863.66\n",
      "epoch : 715/1000, loss = 4026.33\n",
      "epoch : 716/1000, loss = 4167.48\n",
      "epoch : 717/1000, loss = 3733.63\n",
      "epoch : 718/1000, loss = 3943.78\n",
      "epoch : 719/1000, loss = 3707.95\n",
      "epoch : 720/1000, loss = 3956.77\n",
      "epoch : 721/1000, loss = 4125.82\n",
      "epoch : 722/1000, loss = 4068.58\n",
      "epoch : 723/1000, loss = 3814.60\n",
      "epoch : 724/1000, loss = 4167.46\n",
      "epoch : 725/1000, loss = 3903.96\n",
      "epoch : 726/1000, loss = 4059.19\n",
      "epoch : 727/1000, loss = 4073.93\n",
      "epoch : 728/1000, loss = 3830.66\n",
      "epoch : 729/1000, loss = 4054.63\n",
      "epoch : 730/1000, loss = 4020.47\n",
      "epoch : 731/1000, loss = 3949.55\n",
      "epoch : 732/1000, loss = 3717.85\n",
      "epoch : 733/1000, loss = 3866.20\n",
      "epoch : 734/1000, loss = 3825.02\n",
      "epoch : 735/1000, loss = 4094.23\n",
      "epoch : 736/1000, loss = 3998.52\n",
      "epoch : 737/1000, loss = 3916.03\n",
      "epoch : 738/1000, loss = 4128.23\n",
      "epoch : 739/1000, loss = 3590.80\n",
      "epoch : 740/1000, loss = 3961.27\n",
      "epoch : 741/1000, loss = 3905.57\n",
      "epoch : 742/1000, loss = 3498.83\n",
      "epoch : 743/1000, loss = 3756.89\n",
      "epoch : 744/1000, loss = 3899.75\n",
      "epoch : 745/1000, loss = 3750.79\n",
      "epoch : 746/1000, loss = 3812.68\n",
      "epoch : 747/1000, loss = 3715.27\n",
      "epoch : 748/1000, loss = 3810.23\n",
      "epoch : 749/1000, loss = 4252.83\n",
      "epoch : 750/1000, loss = 3716.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 751/1000, loss = 3627.54\n",
      "epoch : 752/1000, loss = 3810.86\n",
      "epoch : 753/1000, loss = 3945.59\n",
      "epoch : 754/1000, loss = 3696.45\n",
      "epoch : 755/1000, loss = 3628.93\n",
      "epoch : 756/1000, loss = 4044.31\n",
      "epoch : 757/1000, loss = 4161.49\n",
      "epoch : 758/1000, loss = 3867.01\n",
      "epoch : 759/1000, loss = 3943.22\n",
      "epoch : 760/1000, loss = 3726.54\n",
      "epoch : 761/1000, loss = 3740.61\n",
      "epoch : 762/1000, loss = 3846.63\n",
      "epoch : 763/1000, loss = 3795.89\n",
      "epoch : 764/1000, loss = 3863.84\n",
      "epoch : 765/1000, loss = 4028.16\n",
      "epoch : 766/1000, loss = 3997.19\n",
      "epoch : 767/1000, loss = 3796.78\n",
      "epoch : 768/1000, loss = 3679.42\n",
      "epoch : 769/1000, loss = 3747.61\n",
      "epoch : 770/1000, loss = 3864.26\n",
      "epoch : 771/1000, loss = 3737.09\n",
      "epoch : 772/1000, loss = 3712.08\n",
      "epoch : 773/1000, loss = 3991.27\n",
      "epoch : 774/1000, loss = 4070.89\n",
      "epoch : 775/1000, loss = 3617.87\n",
      "epoch : 776/1000, loss = 4052.01\n",
      "epoch : 777/1000, loss = 3936.24\n",
      "epoch : 778/1000, loss = 4235.22\n",
      "epoch : 779/1000, loss = 3864.17\n",
      "epoch : 780/1000, loss = 3700.26\n",
      "epoch : 781/1000, loss = 3770.12\n",
      "epoch : 782/1000, loss = 3659.86\n",
      "epoch : 783/1000, loss = 3711.33\n",
      "epoch : 784/1000, loss = 3931.28\n",
      "epoch : 785/1000, loss = 3611.13\n",
      "epoch : 786/1000, loss = 4238.91\n",
      "epoch : 787/1000, loss = 3456.05\n",
      "epoch : 788/1000, loss = 4020.46\n",
      "epoch : 789/1000, loss = 4044.08\n",
      "epoch : 790/1000, loss = 3807.70\n",
      "epoch : 791/1000, loss = 4133.60\n",
      "epoch : 792/1000, loss = 3645.33\n",
      "epoch : 793/1000, loss = 3761.41\n",
      "epoch : 794/1000, loss = 3702.33\n",
      "epoch : 795/1000, loss = 3702.61\n",
      "epoch : 796/1000, loss = 3824.50\n",
      "epoch : 797/1000, loss = 3787.74\n",
      "epoch : 798/1000, loss = 3921.58\n",
      "epoch : 799/1000, loss = 3912.00\n",
      "epoch : 800/1000, loss = 3631.53\n",
      "epoch : 801/1000, loss = 3730.95\n",
      "epoch : 802/1000, loss = 3841.91\n",
      "epoch : 803/1000, loss = 3621.52\n",
      "epoch : 804/1000, loss = 3618.94\n",
      "epoch : 805/1000, loss = 3775.33\n",
      "epoch : 806/1000, loss = 3892.43\n",
      "epoch : 807/1000, loss = 4039.42\n",
      "epoch : 808/1000, loss = 3596.48\n",
      "epoch : 809/1000, loss = 4032.95\n",
      "epoch : 810/1000, loss = 3785.71\n",
      "epoch : 811/1000, loss = 3764.91\n",
      "epoch : 812/1000, loss = 3662.87\n",
      "epoch : 813/1000, loss = 3732.19\n",
      "epoch : 814/1000, loss = 3955.31\n",
      "epoch : 815/1000, loss = 3838.54\n",
      "epoch : 816/1000, loss = 3991.27\n",
      "epoch : 817/1000, loss = 3818.65\n",
      "epoch : 818/1000, loss = 3650.49\n",
      "epoch : 819/1000, loss = 3706.89\n",
      "epoch : 820/1000, loss = 3866.26\n",
      "epoch : 821/1000, loss = 4031.05\n",
      "epoch : 822/1000, loss = 3643.03\n",
      "epoch : 823/1000, loss = 3765.78\n",
      "epoch : 824/1000, loss = 3853.79\n",
      "epoch : 825/1000, loss = 3931.88\n",
      "epoch : 826/1000, loss = 3803.12\n",
      "epoch : 827/1000, loss = 3931.34\n",
      "epoch : 828/1000, loss = 3879.26\n",
      "epoch : 829/1000, loss = 3957.66\n",
      "epoch : 830/1000, loss = 3662.01\n",
      "epoch : 831/1000, loss = 3740.79\n",
      "epoch : 832/1000, loss = 4029.41\n",
      "epoch : 833/1000, loss = 3581.42\n",
      "epoch : 834/1000, loss = 4030.51\n",
      "epoch : 835/1000, loss = 3927.61\n",
      "epoch : 836/1000, loss = 4003.50\n",
      "epoch : 837/1000, loss = 3986.31\n",
      "epoch : 838/1000, loss = 3703.37\n",
      "epoch : 839/1000, loss = 3769.16\n",
      "epoch : 840/1000, loss = 3756.68\n",
      "epoch : 841/1000, loss = 4033.96\n",
      "epoch : 842/1000, loss = 3783.61\n",
      "epoch : 843/1000, loss = 3842.00\n",
      "epoch : 844/1000, loss = 3866.95\n",
      "epoch : 845/1000, loss = 3940.89\n",
      "epoch : 846/1000, loss = 3603.03\n",
      "epoch : 847/1000, loss = 3784.44\n",
      "epoch : 848/1000, loss = 4142.43\n",
      "epoch : 849/1000, loss = 3899.79\n",
      "epoch : 850/1000, loss = 3849.70\n",
      "epoch : 851/1000, loss = 4019.88\n",
      "epoch : 852/1000, loss = 4267.42\n",
      "epoch : 853/1000, loss = 3699.96\n",
      "epoch : 854/1000, loss = 3808.22\n",
      "epoch : 855/1000, loss = 3912.68\n",
      "epoch : 856/1000, loss = 3891.63\n",
      "epoch : 857/1000, loss = 3607.13\n",
      "epoch : 858/1000, loss = 3981.72\n",
      "epoch : 859/1000, loss = 3841.34\n",
      "epoch : 860/1000, loss = 3945.05\n",
      "epoch : 861/1000, loss = 4032.21\n",
      "epoch : 862/1000, loss = 3819.23\n",
      "epoch : 863/1000, loss = 3719.30\n",
      "epoch : 864/1000, loss = 3811.26\n",
      "epoch : 865/1000, loss = 3789.94\n",
      "epoch : 866/1000, loss = 3671.09\n",
      "epoch : 867/1000, loss = 3636.10\n",
      "epoch : 868/1000, loss = 3796.49\n",
      "epoch : 869/1000, loss = 3959.85\n",
      "epoch : 870/1000, loss = 3691.68\n",
      "epoch : 871/1000, loss = 3925.54\n",
      "epoch : 872/1000, loss = 4040.98\n",
      "epoch : 873/1000, loss = 4088.39\n",
      "epoch : 874/1000, loss = 3958.05\n",
      "epoch : 875/1000, loss = 3559.20\n",
      "epoch : 876/1000, loss = 3739.28\n",
      "epoch : 877/1000, loss = 3763.26\n",
      "epoch : 878/1000, loss = 3778.76\n",
      "epoch : 879/1000, loss = 3718.85\n",
      "epoch : 880/1000, loss = 3748.77\n",
      "epoch : 881/1000, loss = 3960.96\n",
      "epoch : 882/1000, loss = 3816.84\n",
      "epoch : 883/1000, loss = 3927.25\n",
      "epoch : 884/1000, loss = 3938.20\n",
      "epoch : 885/1000, loss = 3984.34\n",
      "epoch : 886/1000, loss = 3577.70\n",
      "epoch : 887/1000, loss = 3642.74\n",
      "epoch : 888/1000, loss = 3898.73\n",
      "epoch : 889/1000, loss = 3654.61\n",
      "epoch : 890/1000, loss = 3851.33\n",
      "epoch : 891/1000, loss = 3736.03\n",
      "epoch : 892/1000, loss = 3850.65\n",
      "epoch : 893/1000, loss = 3765.33\n",
      "epoch : 894/1000, loss = 3912.36\n",
      "epoch : 895/1000, loss = 3680.51\n",
      "epoch : 896/1000, loss = 3767.64\n",
      "epoch : 897/1000, loss = 3831.82\n",
      "epoch : 898/1000, loss = 3724.60\n",
      "epoch : 899/1000, loss = 3798.66\n",
      "epoch : 900/1000, loss = 3817.29\n",
      "epoch : 901/1000, loss = 3945.86\n",
      "epoch : 902/1000, loss = 4150.44\n",
      "epoch : 903/1000, loss = 4075.38\n",
      "epoch : 904/1000, loss = 3773.15\n",
      "epoch : 905/1000, loss = 3895.20\n",
      "epoch : 906/1000, loss = 3395.48\n",
      "epoch : 907/1000, loss = 3979.75\n",
      "epoch : 908/1000, loss = 3719.89\n",
      "epoch : 909/1000, loss = 4102.60\n",
      "epoch : 910/1000, loss = 3859.82\n",
      "epoch : 911/1000, loss = 3754.97\n",
      "epoch : 912/1000, loss = 3795.37\n",
      "epoch : 913/1000, loss = 3507.02\n",
      "epoch : 914/1000, loss = 3845.43\n",
      "epoch : 915/1000, loss = 3900.10\n",
      "epoch : 916/1000, loss = 3923.47\n",
      "epoch : 917/1000, loss = 3504.32\n",
      "epoch : 918/1000, loss = 3710.08\n",
      "epoch : 919/1000, loss = 3605.13\n",
      "epoch : 920/1000, loss = 3627.53\n",
      "epoch : 921/1000, loss = 3738.93\n",
      "epoch : 922/1000, loss = 3690.00\n",
      "epoch : 923/1000, loss = 3659.84\n",
      "epoch : 924/1000, loss = 3542.22\n",
      "epoch : 925/1000, loss = 3590.39\n",
      "epoch : 926/1000, loss = 3683.26\n",
      "epoch : 927/1000, loss = 4055.20\n",
      "epoch : 928/1000, loss = 3629.06\n",
      "epoch : 929/1000, loss = 3820.67\n",
      "epoch : 930/1000, loss = 3990.68\n",
      "epoch : 931/1000, loss = 3786.80\n",
      "epoch : 932/1000, loss = 4120.77\n",
      "epoch : 933/1000, loss = 3471.53\n",
      "epoch : 934/1000, loss = 3932.12\n",
      "epoch : 935/1000, loss = 3949.02\n",
      "epoch : 936/1000, loss = 3784.84\n",
      "epoch : 937/1000, loss = 3723.90\n",
      "epoch : 938/1000, loss = 3859.13\n",
      "epoch : 939/1000, loss = 4097.61\n",
      "epoch : 940/1000, loss = 3903.78\n",
      "epoch : 941/1000, loss = 3788.97\n",
      "epoch : 942/1000, loss = 3933.38\n",
      "epoch : 943/1000, loss = 3935.08\n",
      "epoch : 944/1000, loss = 3770.73\n",
      "epoch : 945/1000, loss = 3912.66\n",
      "epoch : 946/1000, loss = 3856.09\n",
      "epoch : 947/1000, loss = 3736.59\n",
      "epoch : 948/1000, loss = 3985.46\n",
      "epoch : 949/1000, loss = 3620.74\n",
      "epoch : 950/1000, loss = 3756.11\n",
      "epoch : 951/1000, loss = 3676.88\n",
      "epoch : 952/1000, loss = 3876.63\n",
      "epoch : 953/1000, loss = 3922.04\n",
      "epoch : 954/1000, loss = 3662.73\n",
      "epoch : 955/1000, loss = 3806.70\n",
      "epoch : 956/1000, loss = 3617.79\n",
      "epoch : 957/1000, loss = 3717.61\n",
      "epoch : 958/1000, loss = 3998.51\n",
      "epoch : 959/1000, loss = 3901.41\n",
      "epoch : 960/1000, loss = 3515.30\n",
      "epoch : 961/1000, loss = 3642.52\n",
      "epoch : 962/1000, loss = 3663.52\n",
      "epoch : 963/1000, loss = 3854.90\n",
      "epoch : 964/1000, loss = 4002.70\n",
      "epoch : 965/1000, loss = 3582.99\n",
      "epoch : 966/1000, loss = 3722.89\n",
      "epoch : 967/1000, loss = 3906.92\n",
      "epoch : 968/1000, loss = 4012.05\n",
      "epoch : 969/1000, loss = 3671.01\n",
      "epoch : 970/1000, loss = 3653.51\n",
      "epoch : 971/1000, loss = 3713.68\n",
      "epoch : 972/1000, loss = 3980.60\n",
      "epoch : 973/1000, loss = 3935.65\n",
      "epoch : 974/1000, loss = 3688.86\n",
      "epoch : 975/1000, loss = 3660.22\n",
      "epoch : 976/1000, loss = 3671.56\n",
      "epoch : 977/1000, loss = 3879.03\n",
      "epoch : 978/1000, loss = 3883.48\n",
      "epoch : 979/1000, loss = 4184.59\n",
      "epoch : 980/1000, loss = 3566.85\n",
      "epoch : 981/1000, loss = 3972.46\n",
      "epoch : 982/1000, loss = 3763.32\n",
      "epoch : 983/1000, loss = 3646.34\n",
      "epoch : 984/1000, loss = 4020.22\n",
      "epoch : 985/1000, loss = 3264.56\n",
      "epoch : 986/1000, loss = 3913.09\n",
      "epoch : 987/1000, loss = 3951.12\n",
      "epoch : 988/1000, loss = 3459.37\n",
      "epoch : 989/1000, loss = 3464.83\n",
      "epoch : 990/1000, loss = 3727.73\n",
      "epoch : 991/1000, loss = 3723.20\n",
      "epoch : 992/1000, loss = 3571.26\n",
      "epoch : 993/1000, loss = 3807.67\n",
      "epoch : 994/1000, loss = 3651.78\n",
      "epoch : 995/1000, loss = 3627.60\n",
      "epoch : 996/1000, loss = 3699.72\n",
      "epoch : 997/1000, loss = 3783.89\n",
      "epoch : 998/1000, loss = 3845.87\n",
      "epoch : 999/1000, loss = 4023.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1000/1000, loss = 3685.67\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    xform_train_loss = 0\n",
    "    embedAE.train()  # Set train flags\n",
    "    corr_xformer.train()\n",
    "\n",
    "    for batch_data, batch_idx in dataloader:\n",
    "        xform_optimizer.zero_grad()\n",
    "        embed, recon = embedAE(batch_data)\n",
    "        Z_batch = corr_xformer(embed[None,:])\n",
    "#         print(W_sup[batch_idx][:,batch_idx].shape, W_mask[batch_idx][:,batch_idx].shape)\n",
    "        xform_loss = xformer_loss(Z_batch[0],\n",
    "                                  torch.from_numpy(hap_origin[batch_idx]),\n",
    "                                  W_sup[batch_idx][:,batch_idx],\n",
    "                                  W_mask[batch_idx][:,batch_idx],\n",
    "                                  lambda_reg=1e2)\n",
    "        xform_loss.backward()\n",
    "#         xform_optimizer.step_and_update_lr()\n",
    "        xform_optimizer.step()\n",
    "        xform_train_loss += xform_loss.item()\n",
    "    \n",
    "    xform_train_loss = xform_train_loss / len(dataloader)\n",
    "    xform_train_loss_arr.append(xform_train_loss)\n",
    "    \n",
    "    hap_origin = det_memhap(SNVdata, embedAE, corr_xformer)  # Initial haplotype memberships\n",
    "    hap_matrix = origin2hap(SNV_matrix, (hap_origin.astype(int) + 1)/2)\n",
    "#     hap_matrix = refine(hap_matrix, SNV_matrix)\n",
    "\n",
    "    mec_curr = MEC(SNV_matrix, hap_matrix)\n",
    "    if mec_curr < mec_min:\n",
    "        mec_min = mec_curr\n",
    "        W_best = readW(SNVdata, embedAE, corr_xformer)\n",
    "        hap_origin_best = 1*hap_origin\n",
    "        hap_matrix_best = 1*hap_matrix\n",
    "        epoch_best = epoch\n",
    "    cpr_curr = compute_cpr(hap_matrix, true_haplo)\n",
    "    if cpr_curr > cpr_max:\n",
    "        cpr_max = cpr_curr\n",
    "    mec.append(mec_curr)\n",
    "    cpr.append(cpr_curr)\n",
    "    \n",
    "    # Display epoch training loss\n",
    "    logger.info(\"epoch : {}/{}, loss = {:.2f}\".format(epoch + 1, num_epoch, xform_train_loss))\n",
    "    print(\"epoch : {}/{}, loss = {:.2f}\".format(epoch + 1, num_epoch, xform_train_loss))\n",
    "    if xformer_savefile and (epoch % 10 == 0):\n",
    "        checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': embedAE.state_dict(),\n",
    "#         'optimizer': xform_optimizer.state_dict(),\n",
    "        }\n",
    "        save_ckp(checkpoint, xformer_savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc8a85e8e20>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc8a8349df0>]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.27238112]\n",
      " [-0.27238112  1.        ]]\n",
      "[(950, 0.5357142857142857), (951, 0.5545112781954887), (963, 0.5507518796992481)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(mec, cpr)\n",
    "plt.xlabel('MEC score')\n",
    "plt.ylabel('CPR')\n",
    "\n",
    "idx_best = np.argsort(mec)[:3]\n",
    "plt.scatter(np.array(mec)[idx_best], np.array(cpr)[idx_best], color='red')\n",
    "\n",
    "print(np.corrcoef(mec, cpr))\n",
    "print(list(zip(np.array(mec)[idx_best], np.array(cpr)[idx_best])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'SNP')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.stem(np.sum(SNV_matrix > 0, axis=0))\n",
    "plt.ylabel('Number of reads covering SNP')\n",
    "plt.xlabel('SNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('xformer_res', rec_hap=hap_matrix_best, rec_hap_origin=hap_origin_best, true_hap=true_haplo)\n",
    "np.savez('sdhap_res', rec_hap=hap_matrix_sdhap, rec_hap_origin=hap_origin_sdhap, true_hap=true_haplo)\n",
    "np.savez('SNV_matrix', SNV_matrix=SNV_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining learned W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([330, 1, 4, 266])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(SNVdata)\n",
    "dataloader_full = DataLoader(SNVdata, batch_size=m,\n",
    "                            num_workers=0)\n",
    "for i, (data, idx) in enumerate(dataloader_full):\n",
    "    SNV_onehot = data\n",
    "SNV_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNV_sim_tensor = torch.squeeze(torch.tensordot(SNV_onehot, SNV_onehot, dims=[[2,3], [2,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 18.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  6.,  0.,\n",
       "         0.,  0.,  3.,  0.,  0., 14.,  0.,  0.,  0.,  0.,  7.,  0.,  0., 10.,\n",
       "         0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 14.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  1.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,\n",
       "         0., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,  6., 13.,\n",
       "         0.,  0.,  3.,  0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNV_sim_tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping reads:  tensor([  1,   4,  11,  22,  26,  30,  33,  38,  41,  43,  53,  60,  72,  76,\n",
      "         89, 107, 113, 137, 138, 139, 142, 146, 161])\n",
      "SNPs covered by read  1  : (array([225, 226, 227, 228, 229, 230, 231, 232, 233, 246, 247, 248, 249,\n",
      "       250, 251, 252, 253, 254]),)\n",
      "SNPs covered by read  tensor(1)  : (array([225, 226, 227, 228, 229, 230, 231, 232, 233, 246, 247, 248, 249,\n",
      "       250, 251, 252, 253, 254]),)  giving overlap of  tensor(18.)\n",
      "SNPs covered by read  tensor(4)  : (array([209, 210, 211, 212, 213, 214, 215, 216, 233, 234, 235, 236, 237]),)  giving overlap of  tensor(1.)\n",
      "SNPs covered by read  tensor(11)  : (array([205, 206, 207, 208, 209, 210, 211, 227, 228, 229, 230, 231, 232,\n",
      "       233, 234]),)  giving overlap of  tensor(7.)\n",
      "SNPs covered by read  tensor(22)  : (array([219, 220, 221, 222, 223, 225, 226, 227, 238, 239, 240, 241, 242,\n",
      "       243, 244, 245, 246, 247, 248, 249]),)  giving overlap of  tensor(7.)\n",
      "SNPs covered by read  tensor(26)  : (array([199, 200, 201, 202, 203, 204, 205, 206, 208, 224, 225, 226, 227,\n",
      "       228, 229, 230]),)  giving overlap of  tensor(6.)\n",
      "SNPs covered by read  tensor(30)  : (array([208, 209, 210, 211, 212, 213, 214, 215, 231, 232, 233, 234, 235,\n",
      "       236]),)  giving overlap of  tensor(3.)\n",
      "SNPs covered by read  tensor(33)  : (array([224, 225, 226, 227, 228, 229, 230, 243, 244, 245, 246, 247, 248,\n",
      "       249, 250, 251, 252, 253]),)  giving overlap of  tensor(14.)\n",
      "SNPs covered by read  tensor(38)  : (array([200, 201, 202, 203, 204, 205, 206, 207, 208, 224, 225, 226, 227,\n",
      "       228, 229, 230, 231]),)  giving overlap of  tensor(7.)\n",
      "SNPs covered by read  tensor(41)  : (array([223, 224, 225, 226, 227, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "       251, 252]),)  giving overlap of  tensor(10.)\n",
      "SNPs covered by read  tensor(43)  : (array([231, 232, 233, 234, 235, 236, 253, 254, 256, 257, 258, 259]),)  giving overlap of  tensor(5.)\n",
      "SNPs covered by read  tensor(53)  : (array([224, 225, 226, 227, 228, 229, 230, 231, 245, 246, 247, 248, 249,\n",
      "       250, 251, 252, 253]),)  giving overlap of  tensor(14.)\n",
      "SNPs covered by read  tensor(60)  : (array([197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 223, 224, 225,\n",
      "       226, 227, 228, 229]),)  giving overlap of  tensor(4.)\n",
      "SNPs covered by read  tensor(72)  : (array([233, 234, 235, 236, 255, 256, 257, 258, 259, 260, 261]),)  giving overlap of  tensor(1.)\n",
      "SNPs covered by read  tensor(76)  : (array([204, 205, 206, 207, 208, 209, 227, 228, 229, 230, 231, 232, 233]),)  giving overlap of  tensor(7.)\n",
      "SNPs covered by read  tensor(89)  : (array([198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 224, 225, 226,\n",
      "       227, 228, 229]),)  giving overlap of  tensor(5.)\n",
      "SNPs covered by read  tensor(107)  : (array([198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 224, 225, 226,\n",
      "       227, 228, 229, 230]),)  giving overlap of  tensor(6.)\n",
      "SNPs covered by read  tensor(113)  : (array([224, 225, 226, 227, 228, 229, 230, 231, 244, 246, 247, 248, 249,\n",
      "       250, 251, 252, 253]),)  giving overlap of  tensor(15.)\n",
      "SNPs covered by read  tensor(137)  : (array([201, 202, 203, 204, 205, 206, 207, 208, 224, 225, 226, 227, 228,\n",
      "       229, 230, 231, 232]),)  giving overlap of  tensor(8.)\n",
      "SNPs covered by read  tensor(138)  : (array([198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 224, 225, 226,\n",
      "       227, 228, 229, 230]),)  giving overlap of  tensor(6.)\n",
      "SNPs covered by read  tensor(139)  : (array([224, 225, 226, 227, 228, 229, 230, 243, 244, 246, 247, 248, 249,\n",
      "       250, 251, 252]),)  giving overlap of  tensor(13.)\n",
      "SNPs covered by read  tensor(142)  : (array([232, 233, 234, 235, 236, 254, 255, 256, 257, 258, 259]),)  giving overlap of  tensor(3.)\n",
      "SNPs covered by read  tensor(146)  : (array([196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 222, 223, 224,\n",
      "       225, 226, 227]),)  giving overlap of  tensor(3.)\n",
      "SNPs covered by read  tensor(161)  : (array([205, 206, 207, 208, 209, 211, 228, 229, 230, 231, 232, 233, 234,\n",
      "       235]),)  giving overlap of  tensor(6.)\n",
      "[ 1.         -0.93333333 -0.46153846 -0.5483871  -0.57142857 -0.79310345\n",
      "  0.27272727 -0.5        -0.13043478 -0.6         0.4        -0.73333333\n",
      " -0.92857143 -0.41666667 -0.65517241 -0.5862069   0.5        -0.40740741\n",
      " -0.5862069   0.23809524 -0.76923077 -0.80645161 -0.53846154]\n",
      "[18.  1.  7.  7.  6.  3. 14.  7. 10.  5. 14.  4.  1.  7.  5.  6. 15.  8.\n",
      "  6. 13.  3.  3.  6.]\n",
      "[ 0. 29. 19. 24. 22. 26.  8. 21. 13. 20.  6. 26. 27. 17. 24. 23.  5. 19.\n",
      " 23.  8. 23. 28. 20.]\n",
      "(18.0, 0.0, 0.9999999999944446) (1.0, 29.0, -0.9333333333302223) (7.0, 19.0, -0.46153846153668643) (7.0, 24.0, -0.5483870967724246) (6.0, 22.0, -0.5714285714265307) (3.0, 26.0, -0.7931034482731273) (14.0, 8.0, 0.2727272727260331) (7.0, 21.0, -0.4999999999982143) (10.0, 13.0, -0.13043478260812855) (5.0, 20.0, -0.5999999999976) (14.0, 6.0, 0.399999999998) (4.0, 26.0, -0.7333333333308889) (1.0, 27.0, -0.9285714285681123) (7.0, 17.0, -0.4166666666649306) (5.0, 24.0, -0.6551724137908442) (6.0, 23.0, -0.5862068965497028) (15.0, 5.0, 0.49999999999750006) (8.0, 19.0, -0.40740740740589854) (6.0, 23.0, -0.5862068965497028) (13.0, 8.0, 0.23809523809410432) (3.0, 23.0, -0.7692307692278108) (3.0, 28.0, -0.8064516129006244) (6.0, 20.0, -0.5384615384594675)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "overlap_idx = torch.nonzero(SNV_sim_tensor[i])\n",
    "print('Overlapping reads: ', torch.squeeze(overlap_idx))\n",
    "print('SNPs covered by read ', i, ' :', np.nonzero(SNV_matrix[i]))\n",
    "\n",
    "for idx in torch.squeeze(overlap_idx):\n",
    "    print('SNPs covered by read ', idx, ' :', np.nonzero(SNV_matrix[idx]), ' giving overlap of ', SNV_sim_tensor[i, idx])\n",
    "\n",
    "print((W_sup[i]).numpy()[overlap_idx[:,0]])\n",
    "print(W_sim[i][overlap_idx[:,0]])\n",
    "print(W_dissim[i][overlap_idx[:,0]])\n",
    "\n",
    "print(*zip(W_sim[i][overlap_idx[:,0]],\n",
    "           W_dissim[i][overlap_idx[:,0]],\n",
    "           W_sup[i].numpy()[overlap_idx[:,0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max diagonal value:  1.0000004\n",
      "Mean W:  0.91996545 SD of W:  0.10455498\n",
      "Deviation from mean:  [[ 0.08003455  0.03896523  0.07481664 ...  0.04924572  0.05444306\n",
      "   0.07937604]\n",
      " [ 0.03896523  0.08003449  0.0616132  ... -0.05670482 -0.04692882\n",
      "   0.03511906]\n",
      " [ 0.07481664  0.0616132   0.08003443 ...  0.02272475  0.02872109\n",
      "   0.07313049]\n",
      " ...\n",
      " [ 0.04924572 -0.05670482  0.02272475 ...  0.08003449  0.07909197\n",
      "   0.05179298]\n",
      " [ 0.05444306 -0.04692882  0.02872109 ...  0.07909197  0.08003479\n",
      "   0.05735528]\n",
      " [ 0.07937604  0.03511906  0.07313049 ...  0.05179298  0.05735528\n",
      "   0.08003455]]\n",
      "[0.99999994 0.93633944 0.8645325  0.94909483 0.92243314 0.84325576\n",
      " 0.90015745 0.9627329  0.8725094  0.9821405  0.8564929  0.86990696\n",
      " 0.95682555 0.9992768  0.88932544 0.92917556 0.90015745 0.9751368\n",
      " 0.92917556 0.90236515 0.9978757  0.8717301  0.9748468 ]\n",
      "[0.9589307  0.99999994 0.98157865 0.75310266 0.93633944 0.95271146\n",
      " 0.9836184  0.84579146 0.8468981  0.73939663 0.8793176  0.8645325\n",
      " 0.9555858  0.8784339  0.9915394  0.8111987  0.8365678  0.93106824\n",
      " 0.8747131  0.95399624 0.7371485  0.98029256 0.94909483 0.9757775\n",
      " 0.9682276  0.8828188  0.92243314 0.772914   0.96129507 0.83935356\n",
      " 0.84325576 0.9849849  0.91427857 0.90015745 0.923599   0.9950311\n",
      " 0.974987   0.85027206 0.9627329  0.809351   0.83365476 0.8725094\n",
      " 0.80613047 0.9821405  0.9381379  0.8309066  0.99412805 0.90902585\n",
      " 0.84826934 0.9950781  0.99708486 0.9919636  0.99171895 0.8564929\n",
      " 0.9944941  0.88695264 0.8342312  0.9797416  0.757083   0.701821\n",
      " 0.86990696 0.7668431  0.9849849  0.9954675  0.8941496  0.91598195\n",
      " 0.9848738  0.9579321  0.9004849  0.8640572  0.98691344 0.92195433\n",
      " 0.95682555 0.7797808  0.8537136  0.97393394 0.9992768  0.80126154\n",
      " 0.6990423  0.79464    0.93106824 0.99567455 0.8940838  0.8815253\n",
      " 0.8221106  0.8152466  0.9521119  0.87805504 0.93959826 0.88932544\n",
      " 0.8148604  0.9925864  0.7797808  0.90902585 0.73939663 0.83055496\n",
      " 0.77470815 0.97185147 0.7396146  0.8587094  0.8257526  0.98208714\n",
      " 0.8853709  0.95507497 0.97185147 0.8727579  0.8054558  0.92917556\n",
      " 0.90641594 0.8940838  0.75011384 0.7458445  0.99072737 0.90015745\n",
      " 0.81447625 0.9863133  0.99642974 0.8001536  0.8940838  0.93257344\n",
      " 0.9930433  0.8257526  0.9814527  0.9175133  0.91808325 0.95117724\n",
      " 0.87650716 0.9872983  0.94877017 0.99072737 0.9893465  0.9824648\n",
      " 0.9702218  0.99078625 0.98942035 0.9776757  0.82678795 0.9751368\n",
      " 0.92917556 0.90236515 0.8913768  0.77815616 0.9978757  0.80626196\n",
      " 0.71553683 0.9947066  0.8717301  0.8221106  0.94135565 0.8152466\n",
      " 0.99733585 0.83071464 0.92035127 0.9614341  0.9534572  0.9770809\n",
      " 0.9638011  0.9888122  0.8239186  0.99655473 0.9987639  0.9748468\n",
      " 0.86173415 0.9779023  0.97525054 0.9102832  0.8628176  0.97907764\n",
      " 0.8391815  0.8235877  0.7606854  0.9617638  0.822869   0.87432224\n",
      " 0.9218277  0.8226142  0.9394234  0.9208447  0.7786186  0.7870507\n",
      " 0.7823891  0.7457703  0.866268   0.775017   0.9004042  0.8002727\n",
      " 0.7575469  0.87763995 0.9940821  0.98515826 0.8458233  0.7310376\n",
      " 0.83633894 0.8782492  0.8932402  0.9665507  0.9471267  0.8538617\n",
      " 0.866268   0.9994156  0.8785956  0.9172814  0.8641371  0.9885182\n",
      " 0.9897851  0.93426114 0.76427585 0.8130762  0.8972557  0.90616405\n",
      " 0.88617575 0.99232554 0.84089965 0.8486684  0.99237376 0.805427\n",
      " 0.8244391  0.8589157  0.8925862  0.86934537 0.8458233  0.8277363\n",
      " 0.96506435 0.8893333  0.90880966 0.76627254 0.78151983 0.745712\n",
      " 0.9925215  0.9953015  0.91609514 0.7984647  0.80179286 0.89582044\n",
      " 0.8042031  0.9658031  0.96748775 0.76415056 0.74174935 0.92229915\n",
      " 0.9820883  0.8042031  0.7915024  0.9690572  0.87844676 0.9060373\n",
      " 0.95993555 0.866268   0.8147549  0.9512161  0.9022258  0.9403093\n",
      " 0.9391404  0.8460743  0.96754366 0.9403093  0.953837   0.9766294\n",
      " 0.8837007  0.7178881  0.9338441  0.71740955 0.82549727 0.90130746\n",
      " 0.82267964 0.74442756 0.92803127 0.9885182  0.7880243  0.8458233\n",
      " 0.9947653  0.99849236 0.77899206 0.75275064 0.8021863  0.99545336\n",
      " 0.7255968  0.7833144  0.9961784  0.8909764  0.71329254 0.9255733\n",
      " 0.8226142  0.74057686 0.835848   0.815747   0.863781   0.9102832\n",
      " 0.9844512  0.99484724 0.9958452  0.8972557  0.82875234 0.7735115\n",
      " 0.7287557  0.8321227  0.9951719  0.7426677  0.78948927 0.9995277\n",
      " 0.994078   0.9966641  0.99500954 0.9670437  0.95276004 0.9139601\n",
      " 0.8256363  0.99531776 0.72788626 0.96974665 0.92553604 0.77783245\n",
      " 0.7287557  0.9984177  0.91068053 0.8857817  0.92818964 0.94876736\n",
      " 0.9649694  0.9712519  0.8395481  0.9339031  0.7171628  0.9732935\n",
      " 0.71640927 0.91094947 0.96754366 0.8632606  0.8730366  0.9550845 ]\n"
     ]
    }
   ],
   "source": [
    "W_full = 1*W_best\n",
    "\n",
    "print('Max diagonal value: ', np.amax(np.diag(W_full)))\n",
    "# print('Diagonal values: ', np.diag(W_full))\n",
    "print('Mean W: ', np.mean(W_full), 'SD of W: ', np.std(W_full))\n",
    "print('Deviation from mean: ', W_full - np.mean(W_full))\n",
    "print(W_full[1, overlap_idx[:,0]])\n",
    "\n",
    "print(W_full[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   6   7   9  13  16  29  35  44  55  65  75  86  87  88  90  91  94\n",
      "  97  98  99 100 104 106 108 117 121 125 128 136 145 151 154 155 156 160\n",
      " 162 166 168 172 173 183 190 197 201 207 209 210 218 220 231 233 248 249\n",
      " 257 259 262 265 269 286 288 292 301 303 307 309 310 311 316 318 320 329]\n",
      "[6.24988949e-12 9.58930671e-01 9.94782090e-01 9.04150188e-01\n",
      " 8.03609848e-01 9.93471980e-01 1.60468272e+00 1.79274758e+00\n",
      " 9.61129427e-01 1.69518249e+00 9.76763606e-01 6.92725420e-01\n",
      " 8.34864318e-01 1.69143413e+00 9.77647781e-01 9.39536273e-01\n",
      " 1.73392175e+00 9.93774295e-01 9.74942982e-01 8.46645296e-01\n",
      " 8.93321514e-01 8.95360649e-01 9.98386562e-01 9.89333212e-01\n",
      " 8.65224004e-01 9.77258384e-01 9.92029667e-01 9.16675150e-01\n",
      " 9.99222338e-01 1.62381093e+00 6.60161316e-01 9.09669757e-01\n",
      " 9.90340531e-01 9.84822810e-01 7.82830954e-01 1.34925506e+00\n",
      " 8.77410412e-01 9.62682128e-01 9.95871305e-01 9.35983777e-01\n",
      " 9.54315424e-01 9.72960413e-01 9.38104510e-01 9.93063807e-01\n",
      " 1.47032918e+00 9.52147901e-01 9.82849002e-01 9.86967564e-01\n",
      " 9.61735070e-01 9.37949121e-01 9.73718166e-01 9.18610334e-01\n",
      " 9.75818872e-01 9.64759946e-01 9.33847487e-01 1.97930568e+00\n",
      " 9.54218924e-01 9.95102763e-01 9.06782687e-01 8.69077921e-01\n",
      " 9.71828103e-01 9.13295925e-01 9.09669757e-01 9.50199902e-01\n",
      " 9.82050717e-01 1.57779430e+00 9.77379799e-01 9.96317863e-01\n",
      " 7.52428353e-01 9.67897475e-01 9.89454091e-01 9.89496529e-01\n",
      " 9.98021662e-01 9.20941830e-01 9.63066936e-01 2.46968508e-01\n",
      " 9.57063854e-01 9.35651958e-01 8.67137551e-01 9.30011690e-01\n",
      " 9.93774295e-01 9.51755345e-01 9.82004404e-01 9.73567724e-01\n",
      " 9.47302759e-01 9.43208814e-01 4.70290629e-01 1.74576365e+00\n",
      " 1.42641618e+00 9.80296969e-01 1.74965298e+00 1.31484558e+00\n",
      " 9.20941830e-01 9.86967564e-01 1.69518249e+00 9.51784074e-01\n",
      " 9.17307913e-01 1.42717191e+00 1.69510190e+00 1.82415133e+00\n",
      " 9.49533165e-01 9.85331118e-01 9.79576528e-01 9.97277856e-01\n",
      " 1.42717191e+00 9.72294331e-01 1.57424171e+00 9.93651092e-01\n",
      " 6.20138909e-01 9.82004404e-01 9.02500331e-01 8.99780393e-01\n",
      " 9.29340839e-01 9.84822810e-01 9.42027271e-01 9.04749453e-01\n",
      " 9.63644624e-01 1.58950705e+00 9.82004404e-01 9.90163505e-01\n",
      " 9.74628091e-01 9.49533165e-01 9.93640184e-01 9.90053773e-01\n",
      " 9.91134584e-01 1.70263547e+00 9.74577367e-01 9.76980269e-01\n",
      " 1.21674060e+00 9.29340839e-01 9.79706347e-01 9.93619800e-01\n",
      " 9.95591879e-01 9.19322014e-01 9.20165479e-01 9.90313530e-01\n",
      " 1.46977576e+00 9.95725513e-01 9.93651092e-01 9.85573769e-01\n",
      " 9.77600992e-01 9.20583427e-01 9.74315107e-01 9.38015759e-01\n",
      " 8.77724826e-01 1.53665767e+00 9.72714365e-01 9.47302759e-01\n",
      " 9.97333944e-01 9.43208814e-01 9.74320710e-01 1.83104301e+00\n",
      " 9.91744220e-01 9.95767236e-01 1.65164105e+00 1.68734739e+00\n",
      " 5.55326376e-01 9.85650301e-01 9.48197484e-01 9.54940021e-01\n",
      " 1.49064908e+00 8.74877572e-01 1.90132325e+00 9.95026529e-01\n",
      " 8.86926591e-01 9.86079574e-01 1.96909362e+00 9.95472431e-01\n",
      " 1.95601511e+00 9.47641373e-01 9.09976959e-01 9.99667645e-01\n",
      " 1.94739574e+00 1.97414213e+00 9.92158771e-01 9.46858704e-01\n",
      " 8.05443168e-01 9.91557002e-01 9.18484151e-01 9.26507354e-01\n",
      " 9.23170090e-01 9.00137663e-01 9.69811380e-01 1.91921866e+00\n",
      " 9.78723466e-01 9.33286071e-01 9.07318413e-01 9.75980818e-01\n",
      " 9.82131779e-01 9.91147339e-01 1.95914471e+00 8.90207231e-01\n",
      " 9.53304410e-01 9.73872900e-01 9.81972039e-01 9.85919654e-01\n",
      " 9.86692071e-01 1.96476716e+00 9.69811380e-01 9.66447115e-01\n",
      " 9.74495053e-01 1.99145442e+00 9.68808234e-01 9.08692479e-01\n",
      " 9.86776352e-01 9.95588541e-01 9.09843028e-01 1.94165152e+00\n",
      " 9.80191946e-01 1.98778075e+00 1.97861087e+00 9.83353078e-01\n",
      " 9.57889497e-01 9.60115850e-01 9.83786583e-01 9.36347961e-01\n",
      " 9.48778391e-01 9.64578271e-01 1.98272902e+00 9.71391201e-01\n",
      " 1.95914471e+00 9.50113773e-01 9.72025216e-01 9.76231396e-01\n",
      " 9.87611651e-01 9.10614789e-01 9.21583891e-01 8.98545682e-01\n",
      " 9.76712704e-01 9.33305860e-01 9.91144061e-01 1.93292379e+00\n",
      " 9.34466302e-01 1.98400599e+00 9.34589446e-01 9.97945964e-01\n",
      " 9.91663218e-01 9.12072837e-01 8.97405326e-01 9.89501297e-01\n",
      " 8.97096932e-01 9.34589446e-01 9.28965151e-01 8.65561306e-01\n",
      " 9.75455940e-01 9.87634838e-01 9.97518241e-01 9.69811380e-01\n",
      " 1.94272053e+00 1.99931383e+00 9.81394112e-01 9.94020402e-01\n",
      " 9.85818565e-01 9.59614396e-01 9.94942784e-01 9.94020402e-01\n",
      " 9.98833954e-01 1.99542540e+00 9.78843927e-01 1.88036716e+00\n",
      " 9.95214760e-01 8.80508780e-01 1.86639182e+00 9.80246723e-01\n",
      " 9.47105944e-01 1.89886403e+00 9.94062960e-01 9.08692479e-01\n",
      " 9.26640213e-01 1.95914471e+00 9.79149818e-01 9.58099425e-01\n",
      " 9.19545770e-01 9.03958678e-01 9.34723318e-01 9.28334296e-01\n",
      " 8.86328399e-01 9.23368454e-01 9.44557667e-01 9.82354224e-01\n",
      " 8.76764357e-01 9.93371964e-01 9.46858704e-01 8.93961728e-01\n",
      " 9.55240130e-01 9.40480411e-01 1.96963996e+00 9.86079574e-01\n",
      " 1.90165931e+00 9.76240993e-01 9.29906189e-01 9.80191946e-01\n",
      " 1.95068491e+00 9.17785287e-01 8.85637820e-01 9.51986790e-01\n",
      " 9.28392053e-01 8.97579074e-01 9.27247405e-01 9.52437580e-01\n",
      " 9.78513896e-01 1.94293052e+00 9.31321859e-01 1.91923199e+00\n",
      " 9.98757362e-01 9.87443745e-01 9.48736370e-01 1.96961755e+00\n",
      " 8.87860596e-01 1.91171185e+00 1.99395072e+00 1.92075181e+00\n",
      " 8.85637820e-01 9.56217945e-01 9.89055634e-01 9.74571407e-01\n",
      " 1.99327022e+00 9.92867231e-01 1.99953204e+00 9.97002721e-01\n",
      " 1.95680326e+00 9.89008248e-01 8.77855241e-01 9.97563481e-01\n",
      " 8.80013704e-01 9.87290919e-01 9.94942784e-01 9.69211161e-01\n",
      " 9.74408507e-01 1.99934149e+00]\n",
      "[6.24988949e-12 1.60468272e+00 1.79274758e+00 1.69518249e+00\n",
      " 1.69143413e+00 1.73392175e+00 1.62381093e+00 1.34925506e+00\n",
      " 1.47032918e+00 1.97930568e+00 1.57779430e+00 2.46968508e-01\n",
      " 4.70290629e-01 1.74576365e+00 1.42641618e+00 1.74965298e+00\n",
      " 1.31484558e+00 1.69518249e+00 1.42717191e+00 1.69510190e+00\n",
      " 1.82415133e+00 9.49533165e-01 1.42717191e+00 1.57424171e+00\n",
      " 6.20138909e-01 1.58950705e+00 9.49533165e-01 1.70263547e+00\n",
      " 1.21674060e+00 1.46977576e+00 1.53665767e+00 1.83104301e+00\n",
      " 1.65164105e+00 1.68734739e+00 5.55326376e-01 1.49064908e+00\n",
      " 1.90132325e+00 1.96909362e+00 1.95601511e+00 1.94739574e+00\n",
      " 1.97414213e+00 1.91921866e+00 1.95914471e+00 1.96476716e+00\n",
      " 1.99145442e+00 1.94165152e+00 1.98778075e+00 1.97861087e+00\n",
      " 1.98272902e+00 1.95914471e+00 1.93292379e+00 1.98400599e+00\n",
      " 1.94272053e+00 1.99931383e+00 1.99542540e+00 1.88036716e+00\n",
      " 1.86639182e+00 1.89886403e+00 1.95914471e+00 1.96963996e+00\n",
      " 1.90165931e+00 1.95068491e+00 1.94293052e+00 1.91923199e+00\n",
      " 1.96961755e+00 1.91171185e+00 1.99395072e+00 1.92075181e+00\n",
      " 1.99327022e+00 1.99953204e+00 1.95680326e+00 1.99934149e+00]\n"
     ]
    }
   ],
   "source": [
    "print(torch.nonzero(W_mask[0]).numpy().flatten())\n",
    "print((W_full - W_sup.numpy())[0])\n",
    "print((W_full - W_sup.numpy())[0, torch.nonzero(W_mask[0]).numpy().flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of reads assigned to hap1:  0.3575757575757576\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of reads assigned to hap1: ', np.sum(hap_origin_best == 1)/len(hap_origin_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000001  0.93095565 0.99049616 ... 0.94733804 0.9545995  0.9987507 ]\n",
      " [0.93095565 1.         0.97079295 ... 0.77023274 0.7830823  0.9229478 ]\n",
      " [0.99049616 0.97079295 1.         ... 0.89939374 0.907809   0.9870748 ]\n",
      " ...\n",
      " [0.94733804 0.77023274 0.89939374 ... 0.99999994 0.9985047  0.95233953]\n",
      " [0.9545995  0.7830823  0.907809   ... 0.9985047  1.         0.9604353 ]\n",
      " [0.9987507  0.9229478  0.9870748  ... 0.95233953 0.9604353  1.        ]]\n",
      "Mean W:  0.8772759 SD of W:  0.15264843\n"
     ]
    }
   ],
   "source": [
    "W_end = readW(SNVdata, embedAE, corr_xformer)\n",
    "print(W_end)\n",
    "print('Mean W: ', np.mean(W_end), 'SD of W: ', np.std(W_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAECSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPR for CAECSeq:  0.9887218045112782\n",
      "MEC score for CAECSeq:  41\n",
      "MEC score for CAECSeq:  41\n"
     ]
    }
   ],
   "source": [
    "SNV_matrix = np.loadtxt(datapath, dtype=int)\n",
    "caec_hap_file = 'generate_data/' + outhead + '/' + outhead + '_Reconstructed_Strains.txt'\n",
    "\n",
    "caec_haplo = read_hap(caec_hap_file)\n",
    "cpr_caec = compute_cpr(caec_haplo, true_haplo)\n",
    "\n",
    "print('CPR for CAECSeq: ', cpr_caec)\n",
    "print('MEC score for CAECSeq: ', MEC(SNV_matrix, caec_haplo))\n",
    "print('MEC score for CAECSeq: ', MEC(SNV_matrix[np.sum(SNV_matrix!=0, axis=1) > 1], caec_haplo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SDHap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SNP positions:  266\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265]]\n"
     ]
    }
   ],
   "source": [
    "def hap_blocks(SNV_matrix: NDArray[(Any, Any), int]) -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    SNV_matrix: NDAray[(Any, Any), int]:\n",
    "        2D read-SNP matrix\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[List[int]]:\n",
    "        List of haplotype blocks, where each block is represented by a list of SNP positions comprising\n",
    "        that block\n",
    "    \"\"\"\n",
    "\n",
    "from collections import deque\n",
    "# FInding haplotype blocks\n",
    "SNP_idx = np.zeros(np.shape(SNV_matrix)[1], dtype=bool)  # Tracking SNP positions visited in BFS\n",
    "SNP_visited = np.zeros(np.shape(SNV_matrix)[1], dtype=bool)  # Tracking SNP positions in queue\n",
    "print('Number of SNP positions: ', len(SNP_idx))\n",
    "blocks = []\n",
    "while not np.all(SNP_idx):\n",
    "    idx_q = deque([np.flatnonzero(~SNP_idx)[0]])\n",
    "    SNP_visited[np.flatnonzero(~SNP_idx)[0]] = True\n",
    "    block_curr = []\n",
    "    while idx_q:\n",
    "        idx = idx_q.popleft()\n",
    "        block_curr.append(idx)\n",
    "        SNP_idx[idx] = True\n",
    "#         print('Covered index: ', idx)\n",
    "        connected_reads = np.flatnonzero(np.sum(SNV_matrix, axis=0))\n",
    "        connected_reads = connected_reads[~SNP_visited]  # Only look at thus far unvisted SNPs\n",
    "        idx_q.extend(connected_reads)\n",
    "        SNP_visited[connected_reads] = True\n",
    "\n",
    "    blocks.append(block_curr)\n",
    "print(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 266)\n",
      "(array([ 8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]), array([ 5, 15, 15, 20, 14, 25, 33, 33, 31, 37, 36, 26, 17,  8,  8,  5,  2]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(330, 266)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_i = SNV_matrix[0]\n",
    "read_j = SNV_matrix[0]\n",
    "\n",
    "np.sum((read_i == read_i)[(read_i != 0) & (read_j != 0)])\n",
    "print(SNV_matrix.shape)\n",
    "print(np.unique(np.sum(SNV_matrix!=0, axis=1), return_counts=True))\n",
    "SNV_matrix = SNV_matrix[np.sum(SNV_matrix!=0, axis=1) > 1]\n",
    "SNV_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 330/330 [00:01<00:00, 309.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# W = squareform(pdist(SNV_matrix, hamming_distance))\n",
    "# m = np.shape(W)[0]\n",
    "\n",
    "num_reads = np.shape(SNV_matrix)[0]\n",
    "W_sim = np.zeros((num_reads, num_reads))\n",
    "W_dissim = np.zeros((num_reads, num_reads))\n",
    "\n",
    "for i, read_i in enumerate(tqdm(SNV_matrix)):\n",
    "    for j, read_j in enumerate(SNV_matrix):\n",
    "        if np.any((read_i != 0) & (read_j != 0)):  # Only if reads overlap\n",
    "            W_sim[i, j] = np.sum((read_i == read_j)[(read_i != 0) | (read_j != 0)])\n",
    "            W_dissim[i, j] = np.sum((read_i != read_j)[(read_i != 0) | (read_j != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of W that is zero:  0.829366391184573\n"
     ]
    }
   ],
   "source": [
    "W_sdhap = (W_sim - W_dissim)/(W_sim + W_dissim + 1e-10)\n",
    "print('Fraction of W that is zero: ', np.sum(W_sdhap == 0)/np.size(W_sdhap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdhap(W_sdhap: NDArray[(Any, Any), float]) -> Tuple[NDArray[int],\n",
    "                                                        NDArray[(Any, Any), int]]:\n",
    "    sval_thr = 1e-1  # eps_th in SDHap\n",
    "    change_thr = 1e-5  # eps_tol in SDHap\n",
    "    m = np.shape(W_sdhap)[0]\n",
    "    V = np.random.randn(m, 2)\n",
    "    V = V/np.linalg.norm(V, axis=1).reshape(m,1)  # Row normalization\n",
    "\n",
    "    col_V = np.shape(V)[1]\n",
    "    rank_V = 1\n",
    "    upd = True  # Set to false when convergence is achieved\n",
    "    obj_curr = np.inf\n",
    "\n",
    "    while upd:\n",
    "        for i in range(m):\n",
    "            V[i] = W_sdhap[i] @ V\n",
    "            V[i] = V[i]/np.linalg.norm(V[i])\n",
    "\n",
    "        rank_V = np.sum(np.linalg.svd(V, compute_uv=False) >= sval_thr)\n",
    "        if(rank_V == col_V):  # V is full column rank\n",
    "            col_V = col_V + 1\n",
    "            rand_col = np.random.rand(m) - 0.5\n",
    "            V = np.append(V, 0.01*rand_col[:,np.newaxis],\n",
    "                          axis=1)\n",
    "            V = V/np.linalg.norm(V, axis=1).reshape(m,1)  # Row normalization\n",
    "\n",
    "        obj_prev = obj_curr\n",
    "        obj_curr = np.trace(W_sdhap @ V @ V.T)\n",
    "\n",
    "        upd = (rank_V != col_V) and (np.abs(1.-obj_curr/obj_prev) >= change_thr)\n",
    "\n",
    "    # Randomized projection\n",
    "    num_rounds = 10*int(np.ceil(np.log2(m)))  # number of rounds\n",
    "    round_x = np.zeros((m, num_rounds), dtype=np.float32)  # x for each round\n",
    "    round_obj = np.zeros(num_rounds)  # ojective for each round\n",
    "    for i in range(num_rounds):\n",
    "        unit_vec = np.random.randn(col_V)\n",
    "    #         unit_vec = unit_vec/np.linalg.norm(unit_vec)\n",
    "    #     print(i, unit_vec, np.sum(V @ unit_vec > 0))\n",
    "        x = -1*np.ones(m, dtype=np.float32)\n",
    "        x[np.where(V @ unit_vec > 0)] = 1\n",
    "\n",
    "        round_x[:, i] = x\n",
    "        round_obj[i] = np.dot(x, W_sdhap @ x)\n",
    "\n",
    "    hap_origin_sdhap = round_x[:, np.argmax(round_obj)]\n",
    "    hap_matrix_sdhap = origin2hap(SNV_matrix, (hap_origin_sdhap.astype(int) + 1)/2) \n",
    "    \n",
    "    return hap_origin_sdhap, hap_matrix_sdhap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:23<00:00,  4.23it/s]\n"
     ]
    }
   ],
   "source": [
    "num_runs_sdhap = 100\n",
    "cpr_arr_sdhap = np.zeros(num_runs_sdhap)\n",
    "mec_arr_sdhap = np.zeros(num_runs_sdhap)\n",
    "\n",
    "for i in tqdm(range(num_runs_sdhap)):\n",
    "    hap_origin_sdhap, hap_matrix_sdhap = sdhap(W_sdhap)\n",
    "    mec_arr_sdhap[i] = MEC(SNV_matrix, hap_matrix_sdhap)\n",
    "    cpr_arr_sdhap[i] = compute_cpr(hap_matrix_sdhap, true_haplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(466.0, 0.8890977443609023), (500.0, 0.8890977443609023), (568.0, 0.8609022556390977)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(mec_arr_sdhap, cpr_arr_sdhap)\n",
    "plt.xlabel('MEC score')\n",
    "plt.ylabel('CPR')\n",
    "\n",
    "idx_sdhap = np.argsort(mec_arr_sdhap)[:3]\n",
    "plt.scatter(np.array(mec_arr_sdhap)[idx_sdhap], np.array(cpr_arr_sdhap)[idx_sdhap], color='red')\n",
    "\n",
    "print(list(zip(np.array(mec_arr_sdhap)[idx_sdhap], np.array(cpr_arr_sdhap)[idx_sdhap])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix:  [[ 1.          0.          0.         ...  0.          0.\n",
      "  -1.        ]\n",
      " [ 0.          1.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          1.         ... -1.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.          0.         -1.         ...  1.         -0.63636364\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ... -0.63636364  1.\n",
      "   0.        ]\n",
      " [-1.          0.          0.         ...  0.          0.\n",
      "   1.        ]]\n",
      "Initial V:  [[-0.97517939 -0.22141624]\n",
      " [ 0.24782062 -0.96880594]\n",
      " [ 0.25045207  0.968129  ]\n",
      " [-0.97337134 -0.22923403]\n",
      " [ 0.83136348 -0.55572904]\n",
      " [-0.31517515 -0.94903352]\n",
      " [ 0.30249725  0.95315026]\n",
      " [ 0.66510332  0.74675134]\n",
      " [ 0.66768094 -0.74444756]\n",
      " [-0.42640187  0.90453383]]\n",
      "k =  2 , r =  3\n",
      "k =  2 , r =  3\n",
      "k =  3 , r =  4\n",
      "k =  3 , r =  4\n",
      "k =  3 , r =  4\n",
      "k =  3 , r =  4\n",
      "k =  3 , r =  4\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  4 , r =  5\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "k =  5 , r =  6\n",
      "Final V =  [[-7.66506002e-01 -4.80124790e-01 -4.23521941e-01 -4.93908801e-02\n",
      "   1.17447973e-02  7.08112648e-04]\n",
      " [-7.83478077e-01  6.11654383e-01 -8.03779057e-02 -7.44944664e-02\n",
      "   5.32966641e-03  1.60615102e-03]\n",
      " [-4.86675456e-01 -8.64782917e-01 -1.09117916e-01  3.01785463e-02\n",
      "   4.97457079e-02  2.32523978e-03]\n",
      " ...\n",
      " [-5.30373180e-01  3.87726454e-01  7.52315703e-01  4.87316411e-02\n",
      "   4.31233597e-03  4.46771651e-04]\n",
      " [ 6.03302934e-01 -4.22400809e-01 -6.74137533e-01 -1.06232088e-02\n",
      "   5.49497231e-02  3.06410675e-03]\n",
      " [ 9.07439921e-01  4.19825816e-01 -1.41440199e-02  8.56015018e-03\n",
      "  -5.07311912e-03 -8.92445426e-05]]\n",
      "[4562.68619585 4236.02050826 4661.38800148 4109.70921953 3810.45634273\n",
      " 4677.27580002 4279.35710636 4345.51549572 4518.07001513 4224.53303088\n",
      " 4656.32858194 4260.18322006 4035.62448291 4680.81005246 4643.18830241\n",
      " 4598.92180665 4439.26902836 4573.08922004 4197.7868249  4042.66873411\n",
      " 4562.21245159 4234.21542511 4461.41553877 4187.73126426 4032.25821142\n",
      " 4649.93829526 4537.65512482 4280.36061695 4425.17539337 4447.10331775\n",
      " 4514.57257654 4505.76230885 4369.78899469 4417.33823892 4437.99560323\n",
      " 4492.87662909 4674.95394097 4260.45071305 4314.39856254 4592.77680695\n",
      " 4686.3379433  4104.19055311 4497.30384865 4268.59178478 4386.52098322\n",
      " 4167.07037007 4523.34716567 4401.61344231 4531.33759267 4413.33330094\n",
      " 4369.25472027 3951.49208448 4390.14359375 4435.7750668  4611.95195239\n",
      " 4220.92737889 4491.56796109 4488.0207298  4691.38847123 4637.24813128\n",
      " 4719.43319322 4610.13501176 4134.79941034 4546.66284976 4599.24832139\n",
      " 4072.42290944 4334.08231498 4285.69974126 4418.39668072 4540.17515513\n",
      " 4483.0825279  4370.27017896 4374.179249   4541.22565186 4470.50646134\n",
      " 4455.22083974 4484.85118924 4379.46857108 4429.95957907 4581.38035766\n",
      " 4368.55690373 4195.11018702 4309.67025462 4255.61643427 4421.09573834\n",
      " 4381.2661723  4711.79319521 4502.30484026 4516.24867697 4239.53646791]\n",
      "[ 1.  1.  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1.  1. -1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1.\n",
      "  1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1.\n",
      " -1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.\n",
      "  1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.\n",
      " -1.  1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1.  1.  1.\n",
      " -1. -1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1.  1.\n",
      " -1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1.\n",
      " -1. -1.  1.  1.  1. -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1.]\n",
      "CPR for SDHap:  0.8759398496240601\n",
      "MEC score for SDHap:  527\n",
      "Fraction of reads assigned to 1st haplotype:  0.5\n"
     ]
    }
   ],
   "source": [
    "sval_thr = 1e-1  # eps_th in SDHap\n",
    "change_thr = 1e-5  # eps_tol in SDHap\n",
    "m = np.shape(SNV_matrix)[0]\n",
    "V = np.random.randn(m, 2)\n",
    "V = V/np.linalg.norm(V, axis=1).reshape(m,1)  # Row normalization\n",
    "\n",
    "col_V = np.shape(V)[1]\n",
    "rank_V = 1\n",
    "upd = True  # Set to false when convergence is achieved\n",
    "obj_curr = np.inf\n",
    "\n",
    "print('Weight matrix: ', W_sdhap)\n",
    "print(\"Initial V: \", V[:10])\n",
    "while upd:\n",
    "    for i in range(m):\n",
    "        V[i] = W_sdhap[i] @ V\n",
    "#         print(\"After multiplication \", i, V[i])\n",
    "        V[i] = V[i]/np.linalg.norm(V[i])\n",
    "#     print(V[:10])\n",
    "#         print('Singular values: ', np.linalg.svd(V, compute_uv=False))\n",
    "    rank_V = np.sum(np.linalg.svd(V, compute_uv=False) >= sval_thr)\n",
    "    if(rank_V == col_V):  # V is full column rank\n",
    "        col_V = col_V + 1\n",
    "        rand_col = np.random.rand(m) - 0.5\n",
    "        V = np.append(V, 0.01*rand_col[:,np.newaxis],\n",
    "                      axis=1)\n",
    "        V = V/np.linalg.norm(V, axis=1).reshape(m,1)  # Row normalization\n",
    "\n",
    "    obj_prev = obj_curr\n",
    "    obj_curr = np.trace(W_sdhap @ V @ V.T)\n",
    "    print(\"k = \", rank_V, \", r = \", col_V)\n",
    "#     print(\"Prev obj = \", obj_prev, \", new obj = \", obj_curr)\n",
    "#     print(\"Percentage drop in objective value = \", 1 - obj_curr/obj_prev)\n",
    "    upd = (rank_V != col_V) and (np.abs(1.-obj_curr/obj_prev) >= change_thr)\n",
    "\n",
    "# Randomized projection\n",
    "print(\"Final V = \", V)\n",
    "num_rounds = 10*int(np.ceil(np.log2(m)))  # number of rounds\n",
    "round_x = np.zeros((m, num_rounds), dtype=np.float32)  # x for each round\n",
    "round_obj = np.zeros(num_rounds)  # ojective for each round\n",
    "for i in range(num_rounds):\n",
    "    unit_vec = np.random.randn(col_V)\n",
    "#         unit_vec = unit_vec/np.linalg.norm(unit_vec)\n",
    "#     print(i, unit_vec, np.sum(V @ unit_vec > 0))\n",
    "    x = -1*np.ones(m, dtype=np.float32)\n",
    "    x[np.where(V @ unit_vec > 0)] = 1\n",
    "\n",
    "    round_x[:, i] = x\n",
    "    round_obj[i] = np.dot(x, W_sdhap @ x)\n",
    "print(round_obj)\n",
    "\n",
    "hap_origin_sdhap = round_x[:, np.argmax(round_obj)]\n",
    "hap_matrix_sdhap = origin2hap(SNV_matrix, (hap_origin_sdhap.astype(int) + 1)/2) \n",
    "cpr_sdhap = compute_cpr(hap_matrix_sdhap, true_haplo)\n",
    "print(hap_origin_sdhap) \n",
    "print('CPR for SDHap: ', cpr_sdhap)\n",
    "print('MEC score for SDHap: ', MEC(SNV_matrix, hap_matrix_sdhap))\n",
    "print('Fraction of reads assigned to 1st haplotype: ', np.sum(hap_origin_sdhap == 1)/len(hap_origin_sdhap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mec_arr_sdhap = np.zeros(np.shape(round_x)[1])\n",
    "cpr_arr_sdhap = np.zeros(np.shape(round_x)[1])\n",
    "\n",
    "for i, x in enumerate(round_x.T):\n",
    "    hap_matrix_i = origin2hap(SNV_matrix, (round_x[:, i].astype(int) + 1)/2)\n",
    "    cpr_arr_sdhap[i] = compute_cpr(hap_matrix_i, true_haplo)\n",
    "    mec_arr_sdhap[i] = MEC(SNV_matrix, hap_matrix_i)\n",
    "    \n",
    "print('CPR for all solutions: ', cpr_arr_sdhap)\n",
    "print('MEC for all solutions: ', mec_arr_sdhap)\n",
    "print('CPR for best solutions: ', cpr_arr_sdhap[mec_arr_sdhap == MEC(SNV_matrix, hap_matrix_sdhap)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_matrix_i = origin2hap(SNV_matrix, (round_x[:, -3].astype(int) + 1)/2)\n",
    "\n",
    "hap_matrix_j = origin2hap(SNV_matrix, (round_x[:, -3].astype(int) + 1)/2)\n",
    "\n",
    "print(hap_matrix_i - hap_matrix_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "recovered_haplo = hap_matrix_sdhap\n",
    "\n",
    "distance_table = np.zeros((len(recovered_haplo), len(true_haplo)))\n",
    "for i, rec_hap in enumerate(recovered_haplo):\n",
    "        for j, true_hap in enumerate(true_haplo):\n",
    "                distance_table[i, j] = hamming_distance(rec_hap, true_hap)\n",
    "\n",
    "index = permutations(range(true_haplo.shape[0]))\n",
    "min_distance = np.inf\n",
    "distance = []\n",
    "for matching in index:\n",
    "        count = 0\n",
    "        for i, match_idx in enumerate(matching):\n",
    "                count += distance_table[i, match_idx]\n",
    "        distance.append(count)\n",
    "        if count < min_distance:\n",
    "                best_matching = matching\n",
    "                min_distance = count\n",
    "# index = (list(index))[np.argmin(np.array(distance))]  # Best one-to-one mapping\n",
    "# print(best_matching)\n",
    "print('CPR: ', 1 - min(distance) / np.size(true_haplo))\n",
    "print(distance_table)\n",
    "print(recovered_haplo)\n",
    "print(true_haplo)\n",
    "print()\n",
    "for hap_origin_i in round_x.T:\n",
    "    hap_matrix_i = origin2hap(SNV_matrix, (hap_origin_i.astype(int) + 1)/2) \n",
    "    print('CPR for approximation: ',  compute_cpr(hap_matrix_i, true_haplo))\n",
    "    print('Haplotypes: \\n', hap_matrix_i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "recovered_haplo = hap_matrix\n",
    "\n",
    "distance_table = np.zeros((len(recovered_haplo), len(true_haplo)))\n",
    "for i, rec_hap in enumerate(recovered_haplo):\n",
    "        for j, true_hap in enumerate(true_haplo):\n",
    "                distance_table[i, j] = hamming_distance(rec_hap, true_hap)\n",
    "\n",
    "index = permutations(range(true_haplo.shape[0]))\n",
    "min_distance = np.inf\n",
    "distance = []\n",
    "for matching in index:\n",
    "        count = 0\n",
    "        for i, match_idx in enumerate(matching):\n",
    "                count += distance_table[i, match_idx]\n",
    "        distance.append(count)\n",
    "        if count < min_distance:\n",
    "                best_matching = matching\n",
    "                min_distance = count\n",
    "# index = (list(index))[np.argmin(np.array(distance))]  # Best one-to-one mapping\n",
    "# print(best_matching)\n",
    "print('CPR: ', 1 - min(distance) / np.size(true_haplo))\n",
    "print(hap_matrix[0]-true_haplo[0])\n",
    "print(hap_matrix[0]-true_haplo[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cp.Variable((m,m), symmetric=True)\n",
    "constraints = [X >> 0]\n",
    "constraints += [\n",
    "    X[i, i] == 1 for i in range(m)\n",
    "]\n",
    "prob = cp.Problem(cp.Minimize(cp.trace(W  @ X)),\n",
    "              constraints)  # Solve SDP relaxation\n",
    "prob.solve(verbose=True)\n",
    "X_opt = X.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goemans-Williamson algorithm\n",
    "X = cp.Variable((m,m), symmetric=True)\n",
    "constraints = [X >> 0]\n",
    "constraints += [\n",
    "    X[i, i] == 1 for i in range(m)\n",
    "]\n",
    "prob = cp.Problem(cp.Minimize(cp.trace(W  @ X)),\n",
    "              constraints)  # Solve SDP relaxation\n",
    "prob.solve()\n",
    "X_opt = X.value\n",
    "\n",
    "num_rounds = 10*int(np.ceil(np.log2(m)))  # number of rounds\n",
    "round_x = np.zeros((m, num_rounds), dtype=np.float32)  # x for each round\n",
    "round_obj = np.zeros(num_rounds)  # ojective for each round\n",
    "for i in range(num_rounds):\n",
    "    unit_vec = np.random.randn(m)\n",
    "    unit_vec = unit_vec/np.linalg.norm(unit_vec)\n",
    "    x = -1*np.ones(m, dtype=np.float32)\n",
    "    eigval, eigvec = np.linalg.eigh(X_opt)\n",
    "    eigval[eigval<0] = 0  # Zeroing out negative eigenvalues\n",
    "    L = eigvec @ np.diag(np.sqrt(eigval))\n",
    "#         L = np.linalg.cholesky(X_opt+ 1e-4*np.eye(m))  # Tikhonov regularization\n",
    "    x[np.where(L.T @ unit_vec > 0)] = 1\n",
    "\n",
    "    round_x[:, i] = x\n",
    "    round_obj[i] = np.dot(x, W @ x)\n",
    "\n",
    "hap_origin = round_x[:, np.argmin(round_obj)]\n",
    "hap_matrix = origin2hap(SNV_matrix, (hap_origin.astype(int) + 1)/2) \n",
    "cpr_sdhap = compute_cpr(hap_matrix, true_haplo)\n",
    "print(hap_origin) \n",
    "print(cpr_sdhap)\n",
    "print(round_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_matrix[:,0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_matrix_greedy = deepcopy(hap_matrix)  # Refined solution\n",
    "mec_curr = MEC(SNV_matrix, hap_matrix)  # Current MEC\n",
    "\n",
    "hap_matrix_new = deepcopy(hap_matrix)\n",
    "while True:\n",
    "    mec_startiter = mec_curr\n",
    "    for j in range(np.shape(hap_matrix)[1]):\n",
    "        hap_matrix_new[:,j] = hap_matrix[:,j][::-1]  # Flip base\n",
    "        mec_new = MEC(SNV_matrix, hap_matrix_new)\n",
    "        if mec_new < mec_curr:  # Update refined solution\n",
    "            mec_curr = mec_new\n",
    "            hap_matrix_greedy[:,j] = hap_matrix[:,j][::-1]\n",
    "        else:  # Reverse base flip\n",
    "            hap_matrix_new[:,j] = hap_matrix[:,j]\n",
    "    if mec_curr == mec_startiter:  # Greedy refinement not improving MEC\n",
    "        break\n",
    "    else:\n",
    "        print(mec_startiter, mec_curr)\n",
    "cpr_sdhap_greedy = compute_cpr(hap_matrix_greedy, true_haplo)\n",
    "print(cpr_sdhap_greedy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing out helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine(hap_matrix, SNV_matrix, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_memhap(SNVdata, embedAE, corr_xformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_matrix = origin2hap(SNVdata, np.concatenate((np.ones(50), -1*np.ones(50))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEC(SNV_matrix, hap_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code snippet to recover full SNV matrix from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_full = DataLoader(SNVdataset,\n",
    "                             batch_size=len(SNVdataset),\n",
    "                             num_workers=0)\n",
    "for i, data in enumerate(dataloader_full):\n",
    "    SNV_tensor = np.squeeze(data.detach().numpy())\n",
    "\n",
    "SNV_matrix = np.zeros((SNV_tensor.shape[0], SNV_tensor.shape[2]))\n",
    "SNV_cov = np.nonzero(np.sum(SNV_tensor, axis=1))\n",
    "SNV_matrix[SNV_cov] = np.argmax(SNV_tensor, axis=1)[SNV_cov] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing out transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 500, 32])\n",
      "torch.Size([1, 500])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  0.1954, -0.0705,  ..., -0.0338,  0.4121,  0.4287],\n",
       "         [ 0.1954,  1.0000,  0.0018,  ...,  0.1492,  0.2856,  0.4612],\n",
       "         [-0.0705,  0.0018,  1.0000,  ...,  0.3570,  0.0546,  0.1313],\n",
       "         ...,\n",
       "         [-0.0338,  0.1492,  0.3570,  ...,  1.0000,  0.2478,  0.2724],\n",
       "         [ 0.4121,  0.2856,  0.0546,  ...,  0.2478,  1.0000,  0.4250],\n",
       "         [ 0.4287,  0.4612,  0.1313,  ...,  0.2724,  0.4250,  1.0000]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((1, 500, 128))\n",
    "CorrTransform = CorrTransformer(d_model=128)\n",
    "CorrTransform(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
