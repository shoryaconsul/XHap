{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadAE(nn.Module):\n",
    "    def __init__(self, nSNP: int):\n",
    "        super().__init__()\n",
    "        latent_dim = int(np.ceil(nSNP/4))  # Size of embedding\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, (4,5), (4,1), (1, 2)),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(32, 64, (1,5), (1,1), 'same'),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(64, 128, (1,3), (1,1), 'same'),\n",
    "            nn.PReLU(),\n",
    "            nn.Flatten(),\n",
    "            )\n",
    "        \n",
    "        self.fc1 = nn.Linear(128*nSNP, latent_dim)\n",
    "        self.fc2 = nn.Linear(latent_dim, 128*nSNP)\n",
    "        self.act1 = nn.PReLU()\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, (1,3), (1,1), (0, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, (1,5), (1,1), (0, 2)),\n",
    "            nn.PReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, (4,5), (4,1), (0,2)),\n",
    "            # nn.PReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_code = self.encoder(x)\n",
    "        x_fc1 = self.fc1(x_code)\n",
    "        x_flatten = self.act1(self.fc2(x_fc1))\n",
    "        x_reshape = x_flatten.view(-1, 128, 1, nSNP)\n",
    "        return x_fc1, self.decoder(x_reshape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 148])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nSNP = 589\n",
    "x = torch.randn(5, 1, 4, nSNP)\n",
    "conv1 = nn.Conv2d(1, 32, (4,5), (4,1), (1, 2))\n",
    "conv1(x).shape\n",
    "\n",
    "x = torch.randn(23, 75392)\n",
    "fc = nn.Linear(128*nSNP, int(np.ceil(nSNP/4)))\n",
    "fc(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNVMatrixDataset(Dataset):\n",
    "    def __init__(self, SNV_file, transform=None):\n",
    "        \"\"\"\n",
    "        SNV_file: txt file containing SNV matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        self.SNV_matrix = np.loadtxt(SNV_file, dtype=int)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.shape(self.SNV_matrix)[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        SNV_row = torch.from_numpy(self.SNV_matrix[idx])\n",
    "        SNV_row_onehot = F.one_hot(SNV_row)[:,1:]\n",
    "        SNV_row_onehot = SNV_row_onehot.type(torch.float32)\n",
    "        SNV_row_onehot = SNV_row_onehot.transpose(1,0)\n",
    "        return SNV_row_onehot[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNVdata = SNVMatrixDataset('Simulated_data/K3/cov15/sample4/simu_erro1_K3_cov15'\\\n",
    "                           '_l5000_iter_7_SNV_matrix.txt')\n",
    "nSNP = SNVdata[0].shape[2] # Number of SNVs\n",
    "num_epoch = 100\n",
    "num_read = len(SNVdata)  # Number of reads\n",
    "batch_size = int(np.ceil(num_read/20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/100, loss = 3955.41\n",
      "epoch : 2/100, loss = 218.17\n",
      "epoch : 3/100, loss = 6.73\n",
      "epoch : 4/100, loss = 0.79\n",
      "epoch : 5/100, loss = 0.45\n",
      "epoch : 6/100, loss = 0.33\n",
      "epoch : 7/100, loss = 0.28\n",
      "epoch : 8/100, loss = 0.25\n",
      "epoch : 9/100, loss = 0.22\n",
      "epoch : 10/100, loss = 0.20\n",
      "epoch : 11/100, loss = 0.18\n",
      "epoch : 12/100, loss = 0.16\n",
      "epoch : 13/100, loss = 0.15\n",
      "epoch : 14/100, loss = 0.14\n",
      "epoch : 15/100, loss = 0.13\n",
      "epoch : 16/100, loss = 0.12\n",
      "epoch : 17/100, loss = 0.11\n",
      "epoch : 18/100, loss = 0.11\n",
      "epoch : 19/100, loss = 0.10\n",
      "epoch : 20/100, loss = 0.09\n",
      "epoch : 21/100, loss = 0.09\n",
      "epoch : 22/100, loss = 0.08\n",
      "epoch : 23/100, loss = 0.08\n",
      "epoch : 24/100, loss = 0.08\n",
      "epoch : 25/100, loss = 0.07\n",
      "epoch : 26/100, loss = 0.07\n",
      "epoch : 27/100, loss = 0.07\n",
      "epoch : 28/100, loss = 0.07\n",
      "epoch : 29/100, loss = 0.06\n",
      "epoch : 30/100, loss = 0.06\n",
      "epoch : 31/100, loss = 0.06\n",
      "epoch : 32/100, loss = 0.06\n",
      "epoch : 33/100, loss = 0.06\n",
      "epoch : 34/100, loss = 0.05\n",
      "epoch : 35/100, loss = 0.05\n",
      "epoch : 36/100, loss = 0.05\n",
      "epoch : 37/100, loss = 0.05\n",
      "epoch : 38/100, loss = 0.05\n",
      "epoch : 39/100, loss = 0.05\n",
      "epoch : 40/100, loss = 0.05\n",
      "epoch : 41/100, loss = 0.05\n",
      "epoch : 42/100, loss = 0.04\n",
      "epoch : 43/100, loss = 0.04\n",
      "epoch : 44/100, loss = 0.04\n",
      "epoch : 45/100, loss = 0.04\n",
      "epoch : 46/100, loss = 0.04\n",
      "epoch : 47/100, loss = 0.04\n",
      "epoch : 48/100, loss = 0.04\n",
      "epoch : 49/100, loss = 0.04\n",
      "epoch : 50/100, loss = 0.04\n",
      "epoch : 51/100, loss = 0.04\n",
      "epoch : 52/100, loss = 0.04\n",
      "epoch : 53/100, loss = 0.04\n",
      "epoch : 54/100, loss = 0.04\n",
      "epoch : 55/100, loss = 0.04\n",
      "epoch : 56/100, loss = 0.04\n",
      "epoch : 57/100, loss = 0.04\n",
      "epoch : 58/100, loss = 0.04\n",
      "epoch : 59/100, loss = 0.03\n",
      "epoch : 60/100, loss = 0.03\n",
      "epoch : 61/100, loss = 0.03\n",
      "epoch : 62/100, loss = 0.03\n",
      "epoch : 63/100, loss = 0.03\n",
      "epoch : 64/100, loss = 0.03\n",
      "epoch : 65/100, loss = 0.03\n",
      "epoch : 66/100, loss = 0.03\n",
      "epoch : 67/100, loss = 0.03\n",
      "epoch : 68/100, loss = 0.03\n",
      "epoch : 69/100, loss = 0.03\n",
      "epoch : 70/100, loss = 0.03\n",
      "epoch : 71/100, loss = 0.03\n",
      "epoch : 72/100, loss = 0.03\n",
      "epoch : 73/100, loss = 0.03\n",
      "epoch : 74/100, loss = 0.03\n",
      "epoch : 75/100, loss = 0.03\n",
      "epoch : 76/100, loss = 0.03\n",
      "epoch : 77/100, loss = 0.03\n",
      "epoch : 78/100, loss = 0.03\n",
      "epoch : 79/100, loss = 0.03\n",
      "epoch : 80/100, loss = 0.03\n",
      "epoch : 81/100, loss = 0.03\n",
      "epoch : 82/100, loss = 0.03\n",
      "epoch : 83/100, loss = 0.03\n",
      "epoch : 84/100, loss = 0.03\n",
      "epoch : 85/100, loss = 0.03\n",
      "epoch : 86/100, loss = 0.03\n",
      "epoch : 87/100, loss = 0.03\n",
      "epoch : 88/100, loss = 0.03\n",
      "epoch : 89/100, loss = 0.03\n",
      "epoch : 90/100, loss = 0.03\n",
      "epoch : 91/100, loss = 0.03\n",
      "epoch : 92/100, loss = 0.03\n",
      "epoch : 93/100, loss = 0.03\n",
      "epoch : 94/100, loss = 0.03\n",
      "epoch : 95/100, loss = 0.03\n",
      "epoch : 96/100, loss = 0.03\n",
      "epoch : 97/100, loss = 0.03\n",
      "epoch : 98/100, loss = 0.03\n",
      "epoch : 99/100, loss = 0.03\n",
      "epoch : 100/100, loss = 0.03\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(SNVdata, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #  use gpu if available\n",
    "\n",
    "embedAE = ReadAE(nSNP).to(device)  # Create and send model to device\n",
    "\n",
    "optimizer = optim.Adam(embedAE.parameters(), lr=1e-2)\n",
    "MSE = nn.MSELoss()\n",
    "train_loss_arr = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    loss = 0\n",
    "    for batch_data in dataloader:\n",
    "        optimizer.zero_grad()  # reset the gradients back to zero\n",
    "        _, recon = embedAE(batch_data) # compute reconstructions\n",
    "        train_loss = MSE(recon, batch_data)  # compute training reconstruction loss\n",
    "        train_loss.backward()  # compute accumulated gradients\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()  # add the mini-batch training loss to epoch loss\n",
    "    loss = loss / len(dataloader)  # compute the epoch training loss\n",
    "    train_loss_arr.append(loss)\n",
    "\n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.2f}\".format(epoch + 1, num_epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.0.weight torch.Size([32, 1, 4, 5])\n",
      "encoder.0.bias torch.Size([32])\n",
      "encoder.1.weight torch.Size([1])\n",
      "encoder.2.weight torch.Size([64, 32, 1, 5])\n",
      "encoder.2.bias torch.Size([64])\n",
      "encoder.3.weight torch.Size([1])\n",
      "encoder.4.weight torch.Size([128, 64, 1, 3])\n",
      "encoder.4.bias torch.Size([128])\n",
      "encoder.5.weight torch.Size([1])\n",
      "fc1.weight torch.Size([136, 69376])\n",
      "fc1.bias torch.Size([136])\n",
      "fc2.weight torch.Size([69376, 136])\n",
      "fc2.bias torch.Size([69376])\n",
      "act1.weight torch.Size([1])\n",
      "decoder.0.weight torch.Size([128, 64, 1, 3])\n",
      "decoder.0.bias torch.Size([64])\n",
      "decoder.1.weight torch.Size([1])\n",
      "decoder.2.weight torch.Size([64, 32, 1, 5])\n",
      "decoder.2.bias torch.Size([32])\n",
      "decoder.3.weight torch.Size([1])\n",
      "decoder.4.weight torch.Size([32, 1, 4, 5])\n",
      "decoder.4.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in embedAE.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcdc4745820>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
